"use strict";(self.webpackChunkproper_code=self.webpackChunkproper_code||[]).push([[9450],{6029:e=>{e.exports=JSON.parse('{"blogPosts":[{"id":"/2023/05/22/docusaurus","metadata":{"permalink":"/2023/05/22/docusaurus","source":"@site/blog/2023/05-22-docusaurus.md","title":"Docusaurus","description":"Finally an update to the UI for this blog.","date":"2023-05-22T00:00:00.000Z","formattedDate":"May 22, 2023","tags":[{"label":"Blog","permalink":"/tags/blog"},{"label":"Update","permalink":"/tags/update"}],"readingTime":1.015,"hasTruncateMarker":true,"authors":[],"frontMatter":{"title":"Docusaurus","tags":["Blog","Update"]},"nextItem":{"title":"Blog Update: English Only","permalink":"/2022/01/06/english"}},"content":"Finally an update to the UI for this blog.\\n\\n\x3c!-- truncate --\x3e\\n\\nI\'ve been working at [AppDirect](https://www.appdirect.com/) for 4 years now and over the past year we\'ve been trying to remake our internal and external documentation.\\n\\nIt all started with a hackathon where myself and 3 other people decided to try out Docusaurus for our internal glossary. Within a little more than a day, we had the glossary up and running in Docusaurus, with a couple of extra features.\\n\\nA couple of weeks later, we decided to convert all of our internal documentation to use Docusaurus. Since I had experience setting it up, I started the project. Our UI and UX teams helped in making it more attractive and personalized. They have also started converting our external developer documentation to use Docusaurus as well.\\n\\nDuring all this time, I\'ve been thinking about my blog and how it doesn\'t look so good when I compared it with just what\'s out of the box for Docusaurus. So over the past few weeks, I\'ve converted my own website to Docusaurus.\\n\\nAdding features will be a lot easier, adding content will be a lot easier. Hopefully that should give me some incentive to create more of it."},{"id":"/2022/01/06/english","metadata":{"permalink":"/2022/01/06/english","source":"@site/blog/2022/01-06-english.md","title":"Blog Update: English Only","description":"In an effort to reduce the maintenance time for this blog and hopefully have a little more content. I\'ve decided to remove the french translations of my blog posts.","date":"2022-01-06T00:00:00.000Z","formattedDate":"January 6, 2022","tags":[{"label":"Blog","permalink":"/tags/blog"},{"label":"Update","permalink":"/tags/update"}],"readingTime":0.275,"hasTruncateMarker":false,"authors":[],"frontMatter":{"title":"Blog Update: English Only","tags":["Blog","Update"]},"prevItem":{"title":"Docusaurus","permalink":"/2023/05/22/docusaurus"},"nextItem":{"title":"Advent of Code 2021 Recap","permalink":"/2022/01/05/advent2021"}},"content":"In an effort to reduce the maintenance time for this blog and hopefully have a little more content. I\'ve decided to remove the french translations of my blog posts.\\n\\nI\'m expecting to add a couple more features as well and make the site prettier, since it should now be a little easier to do so."},{"id":"/2022/01/05/advent2021","metadata":{"permalink":"/2022/01/05/advent2021","source":"@site/blog/2022/01-05-advent2021.md","title":"Advent of Code 2021 Recap","description":"2021 is now over and I have completed the advent of code in Rust. Here are my findings.","date":"2022-01-05T00:00:00.000Z","formattedDate":"January 5, 2022","tags":[{"label":"Challenges","permalink":"/tags/challenges"},{"label":"Advent","permalink":"/tags/advent"},{"label":"Rust","permalink":"/tags/rust"}],"readingTime":1.695,"hasTruncateMarker":true,"authors":[],"frontMatter":{"title":"Advent of Code 2021 Recap","tags":["Challenges","Advent","Rust"]},"prevItem":{"title":"Blog Update: English Only","permalink":"/2022/01/06/english"},"nextItem":{"title":"Advent of Code 2021","permalink":"/2021/11/20/advent2021"}},"content":"2021 is now over and I have completed the advent of code in Rust. Here are my findings.\\n\\n\x3c!-- truncate --\x3e\\n\\n### Rust\\nRust has its quirks when writing the code, but the error messages are very clear. \\n\\nHaving worked in other pointer/reference handling languages (C++ mainly), it was pretty easy to pick up. \\n\\nAs I was expecting, performance is absolutely incredible as well.\\n\\nMaking trees and graphs is pretty complicated though. Since Rust does a lot of checks on variable lifetimes and borrows as well as stack size, you can\'t easily have pointers to nodes within a node structure. Most of the problems I ended up a pattern that seems to be called a \\"memory arena\\" by the Rust community. In this pattern you keep a list of all the nodes, usually in a vector for instant random access, and each node contains the index of other nodes it\'s referring to instead of a pointer to it. If the tree/graph doesn\'t change, it\'s pretty easy to use, but if you need to modify it, it becomes a little more complicated although doable.\\n\\n### Problems were overall good\\nMost of the problems were pretty easy to solve algorithmically. Some problems took me more time as I mentioned above because I\'m not used to creating trees and graphs in Rust. Another notable mention is problem 24 which is a little more complicated to solve and takes a lot of experimentations before you can figure out how you\'re supposed to reduce the search space. I wished they didn\'t put that as the last problem.\\n\\nWhat I missed the most out of all the problems compared to previous years was a set a problem to made you evolve a previous solution. This was usually done as a assembly-like language you had to write a computer emulator for. I hope they bring something similar back in future years.\\n\\n### Final thoughts\\nOverall very fun and Rust was a blast to use.\\n\\nAll my code and inputs are available in [advent2021](https://github.com/lavoiecsh/lavoiecsh.github.io/tree/master/code/advent2021) for those interested."},{"id":"/2021/11/20/advent2021","metadata":{"permalink":"/2021/11/20/advent2021","source":"@site/blog/2021/11-20-advent2021.md","title":"Advent of Code 2021","description":"Another year, another advent, more code!","date":"2021-11-20T00:00:00.000Z","formattedDate":"November 20, 2021","tags":[{"label":"Challenges","permalink":"/tags/challenges"},{"label":"Advent","permalink":"/tags/advent"}],"readingTime":0.975,"hasTruncateMarker":true,"authors":[],"frontMatter":{"title":"Advent of Code 2021","tags":["Challenges","Advent"]},"prevItem":{"title":"Advent of Code 2021 Recap","permalink":"/2022/01/05/advent2021"},"nextItem":{"title":"Thinking in resolvers","permalink":"/2020/10/15/thinking-in-resolvers"}},"content":"Another year, another advent, more code!\\n\\n\x3c!-- truncate --\x3e\\n\\nThis will be my fourth year attempting the different challenges:\\n\\n- 2018: completed everything in C#\\n- 2019: partially completed in Haskell\\n- 2020: completed everything in C++\\n- 2021: this will be the year of Rust\\n\\nDoing code challenges in C++ is a breeze. It\'s super performant so you can get away with some slight imperfections in your code and still get some ridiculously fast execution times. Newer version syntaxes allow for easier readability and less code writing as well.\\n\\nDue to lack of time, I didn\'t want to embark on another functional language challenge as they usually require a lot of knowledge of the language if you want to get some decent performances.\\n\\nBut I still wanted to learn a new language. So I chose Rust.\\n\\nIt\'s another imperative language similar to C and C++, but with a cleaner syntax.\\n\\nSome quick tests have shown it has some pretty incredible performances as well, no wonder it\'s used in operating systems.\\n\\nI converted some problems from 2019 in Rust [here](https://github.com/lavoiecsh/lavoiecsh.github.io/tree/master/code/advent2019/rust) to get a hang of it.\\n\\nNew solutions will come hopefully each day in [advent2021](https://github.com/lavoiecsh/lavoiecsh.github.io/tree/master/code/advent2021)"},{"id":"/2020/10/15/thinking-in-resolvers","metadata":{"permalink":"/2020/10/15/thinking-in-resolvers","source":"@site/blog/2020/10-15-thinking-in-resolvers.md","title":"Thinking in resolvers","description":"Everything in GraphQL revolves around resolvers. It\'s important to understand this to better develop application exposing GraphQL APIs.","date":"2020-10-15T00:00:00.000Z","formattedDate":"October 15, 2020","tags":[{"label":"Technologies","permalink":"/tags/technologies"},{"label":"GraphQL","permalink":"/tags/graph-ql"}],"readingTime":7.815,"hasTruncateMarker":true,"authors":[],"frontMatter":{"title":"Thinking in resolvers","tags":["Technologies","GraphQL"]},"prevItem":{"title":"Advent of Code 2021","permalink":"/2021/11/20/advent2021"},"nextItem":{"title":"Advent of Code 2019","permalink":"/2019/12/02/advent2019"}},"content":"Everything in GraphQL revolves around resolvers. It\'s important to understand this to better develop application exposing GraphQL APIs.\\n\\n\x3c!-- truncate --\x3e\\n\\n## Table of Contents\\n1. [Resolver Anatomy](#resolver-anatomy)\\n1. [Field within a type](#field-within-a-type)\\n1. [The special (but not so special) cases](#the-special-but-not-so-special-cases)\\n1. [Federation](#federation)\\n1. [Directives](#directives)\\n\\n## Resolver Anatomy\\nA resolver is a function returning the value of a field within a type. It takes in four arguments:\\n1. parent: the instance returned by the parent resolver\\n1. args/input: any additional input to the field (usually what\'s in parentheses in the schema)\\n1. context: an object built by the server before resolver each query that usually contains globally accessible information and information about the current query\\n1. info: information about the fields, types, queries being executed\\n\\nMost of the time we use the first three arguments to resolve a field. The fourth argument is usually discarded as the information is seldom useful.\\n\\nFor most GraphQL server implementations, resolvers are referenced within a hierarchy of Type to field.\\n\\n## Field within a type\\nEach field within a type uses a resolver to define the value to return for this field and a particular instance of the parent type. Looking at the following schema:\\n```graphql\\ntype Product {\\n  id: ID!\\n  type: ProductType!\\n  name(locale: Locale): String\\n}\\n```\\n\\nThis product type has three fields: id, type and name. Assuming the user wants all three fields to be returned and the product instance is already resolved, three resolvers will be called to get the value for aech field. In each case the parent parameter will be the instance of the product type that has been resolved previously and the context will receive what was built by the server. Additionally, the args parameter will be empty for the id and type fields, and contain the given locale for the name field. Each of these resolvers will be included in the Product type.\\n\\nThere is a default resolver that takes the value from the parent if that parent has a property matching the field we are resolving. You can override this resolver to add more logic when resolving the field:\\n- Not returning the value if the user doesn\'t have sufficient permissions\\n- Returning a different value in some cases\\n- Returning a calculated value\\n- Fetching data from a different table/collection in your database\\n\\n## The special (but not so special) cases\\nQuery, Mutation and Subscription types in GraphQL let you define the basic API you are exposing to the clients. These are referred to as the \\"root\\" types and are predefined by the specification.\\n\\nThese are still types in the sense that they contain fields that will be resolved through resolvers just like any other field within a type. The only different is that there is no default resolver for these types and you must then write the resolvers yourself. As for the arguments, they function the same way as for other field resolvers, although the parent parameter will be defined by the GraphQL implementation you use (usually null or an empty object).\\n\\nSince these are still types from the GraphQL point of view, each query is a field with a resolver within the Query type, each mutation is a field with a resolver within the Mutation type, and each subscription is a field with a resolver within the Subscription type.\\n\\n## Federation\\nFederation lets you define fields on types outside your domain and lets you return references to types outside your domain for fields in your domain. The gateway will handle which resolver to call for each field.\\n\\n### Allowing extensions\\nWhen creating a type that could be extended by other services, you need to use the `@key` directive to indicate which fields will be exposed to the other services.\\n\\n```graphql\\ntype Product @key(fields: \\"id state\\") {\\n  id: ID!\\n  state: ProductState!\\n  type: ProductType!\\n  ...\\n}\\n```\\nThe key in this case will contain the id and state fields, but not the type field.\\n\\n### Extending\\nWhen extending a type to add a new field, you create an extended type in your schema using the `@extends` keyword. The `@key` and `@external` directives indicates the fields that are required for you to be able to resolve your additional field, and that these are coming from another service.\\n\\n```graphql\\n@extends type Product @key(fields: \\"id state\\") {\\n  id: ID! @external\\n  state: ProductState! @external\\n  integrationConfiguration: IntegrationConfiguration\\n}\\n```\\n\\nWhen resolving the integrationConfiguration field for a product, the gateway will send the id and state in the parent parameter of the resolver, allowing you to correctly resolve the integrationConfiguration field. This resolver will belong to the Product type within the integration configuration service.\\n\\n### Referencing\\nWhen referencing an outside type within your schema, you need to include an __typename and all the key fields so that the gateway can resolve this reference. For example, again from the integration configuration service:\\n```graphql\\ntype IntegrationConfiguration {\\n  id: ID!\\n  state: ProductState!\\n  products: [Product]\\n}\\n```\\n\\nTo create a backwards reference to the products linked to this integration configuration, you need to create a resolver named `products` in the IntegrationConfiguration type. This resolver will need to return an array of objects containing the id and state of the referenced product as well as the type.\\n```json\\n{\\n  \\"__typename\\": \\"Product\\",\\n  \\"id\\": \\"123\\",\\n  \\"state\\": \\"WORKING\\"\\n}\\n```\\n\\n### Resolving References\\nWith the resolved value above, the gateway then turns to the product service and asks to resolve the reference through the `__resolveReference` resolver. This is a special case resolver which only takes the parent and context arguments. The parent will contain the value for the key fields returned by the other service and the context will be generated just like any other resolver. This special resolver will be part of the `Product` type within the product service.\\n\\n### Notes on Queries\\nWith federation, queries will be coming to your service from the GraphQL gateway. These are usually a little obscure but it\'s useful to know what they look like so you can use them when testing resolvers without the gateway.\\n```graphql\\nquery {\\n  _entities(representations: [\\n    {\\n      __typename: \\"Product\\"\\n      id: \\"123\\"\\n      state: WORKING\\n    }\\n  ]) {\\n    ... on Product {\\n      type\\n    }\\n  }\\n}\\n```\\n\\nThis kind of query is used by the gateway to resolve references to objects and additional fields defined in another service with federation. The representations in the `_entities` query defines all the parent objects with all the required fields to resolve whatever was requested by the client.\\n\\nSince the type field resides in the Product type definition for the product service, it will first resolve the product through the `__resolveReference` resolver, passing in the given representation. It will then resolve the type field on the result. This can be used to ensure our `__resolveReference` resolver works as expected.\\n\\nIf we ask for the integrationConfiguration field instead of the type field in the same query, we get a query being sent to the integration configuration service to resolve the integration configuration. This will call the integrationConfiguration resolver within the Product type in the intgeration configuration service and pass as parent the given representation. This can be used to test additional fields for extended types in isolation, without needing to run the gateway and the service where the type was originally defined.\\n\\nRepresentations must contain all the fields defined in the key directive for a type as well as the `__typename`. Notice how this is identical to what we return when we want to resolve a type belonging to another service.\\n\\n## Directives\\nOnce resolvers are clear, you can start to look at directives. A directive is an additional element to the schema to add logic around a resolver. Some directives are predefined by the specification. Federation adds some we previously mentioned:\\n- The `@extends` directive on a type indicates the type we are referencing is part of another service within the global schema. This ensures there are no collisions within a federated schema.\\n- The `@key` directive on a type ensures the key fields are resolved for an instance and extracts them for referencing within federation.\\n- The `@external` directive on a field indicates the field is not resolved by our service.\\n\\nDirectives are executed not when the field is resolved but when the server is started. This means you do not have access to the parent, input and context at the moment the field is resolved, but you can exchange the defined resolver with another one. For those fluent in Object-Oriented design patterns, you can think of them as decorators.\\n\\nDirectives can act on a multitude of elements within a GraphQL schema, from the schema itself, to types, fields, enum, enum values, scalars, arguments, input fields, etc. Typical use cases for using directives on fields is to perform validations on the input or verifying the user has the correct authorization before calling the resolver. They can also be used to modify the arguments being sent, such as lower-casing strings, or modify the return value from the resolver, suach as formatting or translating the output.\\n\\nWhen adding validations to a query or mutation, remember these are still fields within a Query or Mutation type. You need to define a field directive on the query o rmutation. Within the directive implementation, you will then have access to the resolver function being called and can wrap it to validate the input being sent to the query or mutation."},{"id":"/2019/12/02/advent2019","metadata":{"permalink":"/2019/12/02/advent2019","source":"@site/blog/2019/12-02-advent2019.md","title":"Advent of Code 2019","description":"December has come around and it\'s time for the Advent of Code again!","date":"2019-12-02T00:00:00.000Z","formattedDate":"December 2, 2019","tags":[{"label":"Challenges","permalink":"/tags/challenges"},{"label":"Advent","permalink":"/tags/advent"}],"readingTime":0.7,"hasTruncateMarker":true,"authors":[],"frontMatter":{"title":"Advent of Code 2019","tags":["Challenges","Advent"]},"prevItem":{"title":"Thinking in resolvers","permalink":"/2020/10/15/thinking-in-resolvers"},"nextItem":{"title":"The problem with java isn\'t the language, it\'s the rest","permalink":"/2019/11/26/java"}},"content":"December has come around and it\'s time for the Advent of Code again!\\n\\n\x3c!-- truncate --\x3e\\n\\nLast year I completed the challenges using C#, TDD, and way to much architecture. I was also creating a blog post each day to track my progress.\\n\\nThis year I challenged myself to use Haskell and not overthink the problems. I won\'t be creating a blog post each day though, but one every once in a while.\\n\\nAs we\'re December 2nd, I\'ve already completed 2 challenges and here are my thoughts so far on using Haskell:\\n- Syntax is increadibly easy and readable\\n- Thinking in functional gives a good break from day to day OO programming\\n- Understanding how to interact with Monads is complicated but is becoming easier each day\\n\\nAs with last year, all my code will be available online: https://github.com/lavoiecsh/lavoiecsh.github.io/tree/master/code/advent2019"},{"id":"/2019/11/26/java","metadata":{"permalink":"/2019/11/26/java","source":"@site/blog/2019/11-26-java.md","title":"The problem with java isn\'t the language, it\'s the rest","description":"I\'ve been working with Java as a main language for over a year now, and have come to the realization that the biggest problem people have with Java isn\'t the language itself, but every other thing you need to make enterprise software with Java. As I\'ve also worked a lot with C#, I\'ll draw some parallels between the two.","date":"2019-11-26T00:00:00.000Z","formattedDate":"November 26, 2019","tags":[{"label":"Technologies","permalink":"/tags/technologies"},{"label":"Java","permalink":"/tags/java"}],"readingTime":8.395,"hasTruncateMarker":true,"authors":[],"frontMatter":{"title":"The problem with java isn\'t the language, it\'s the rest","tags":["Technologies","Java"]},"prevItem":{"title":"Advent of Code 2019","permalink":"/2019/12/02/advent2019"},"nextItem":{"title":"React + Redux + Saga","permalink":"/2019/11/04/react"}},"content":"I\'ve been working with Java as a main language for over a year now, and have come to the realization that the biggest problem people have with Java isn\'t the language itself, but every other thing you need to make enterprise software with Java. As I\'ve also worked a lot with C#, I\'ll draw some parallels between the two.\\n\\n\x3c!-- truncate --\x3e\\n\\n## Spring\\nSpring is a big beast in the Java universe, and it\'s hard to find replacements for it unless you start stringing together a bundle of different third-party libraries that handle one of Spring\'s features each. Spring mainly used to handle dependency injection and API server creation. Apart from being very resource hungry and taking a lot of time to start up, dependency injection is usually done through convention, meaning it checks for interfaces and classes with names that follow a specific convention, forcing you to use this convention. Configuring this is either impossible or very difficult, so you end up hacking a bit with your names if you want to override this. One advantage of Spring is in routing, which doesn\'t use convention unlike C#.\\n\\nIn the C# world, Spring has essentially been replaced by .NET Core, which offers the same API server creation, dependency injection but also handles server-side rendering through Razor (which requires a library like Wicket or Struts for the equivalent in Java). The main advantage I find though, is that the dependency injection for C# uses a configuration basis instead of convention. This makes it easier to handle specific cases of dependency injection. Although the MVC model in .NET Core uses convention, overriding this convention is actually pretty simple.\\n\\n### Database queries\\nSpring also offer JdbcTemplate to interact with your database, or you can use another library, Hibernate, if you want a higher language database access. For both of these, you often end up writing SQL code textually, at least for some queries, which couples your application to the database you\'re using, be it MySQL, SQLite or other. If you want to have tests running on another database (such as H2), chances are some of the SQL code you have won\'t work with it and you\'ll end up either having to write a different query for each implementation or writing a less efficient or readable query that can handle both implementations.\\n\\nC# on the hand introduces EntityFramework (and EntityFrameworkCore). This library offers a wide variety of implementations for SQL database, and the code you write is implementation-agnostic since it translates LINQ into SQL code dependending on the implementation. This makes it very easy to change between a production database and a unit test database without having to change the code.\\n\\n## Ant/Maven/Gradle\\nSince we tend to not want to write stuff others may have written better, we want the possibility to just get an external library and use it in our code. Since Java doesn\'t have a dependency management system, your choices are to copy the library into your project and update it manually or to rely on an external tool to do the downloading whenever you need it. Your choices of external tool here are usually Maven or Gradle, but there are a lot more, each with their own configuration file language and template and way to invoke it. These tool also handle compilation for large multiple package projects, and other tools also handle this part only like Ant.\\n\\nAll these different tools mean that you can\'t have a unified and approved way of handling your compilation and since each tool is developped by different people, may have different bugs and finding information for a tool is often mixed up with information for another tool (Maven and Gradle being the two main culprits here). Add to this the fact that you may even have to write scripts on top of the tool (Gradle Wrapper) to get the tool to work for you.\\n\\nSince java doesn\'t have files to define packages and everything is done through folder structure, each of these tool will define a separate configuration file for each package containing the required third-party dependencies.\\n\\nIf we compare this to C#, there is only one unified way to compile and include dependencies and it\'s handle by a single tool. C# forces you to have a file for each package (project) in your project (solution) which defines all the included files in the package and each required dependency, between projects as well as third-party libraries. There\'s a single compilation tool to handle everything so finding information about it is very easy.\\n\\n## JVM\\nAlthough the JVM offers the possibility to easily port your application to basically any processor architecture, it comes with a large performance cost, especially when starting up an application. This doesn\'t really affect the normal operation of your API server, but does add a lot of overhead if you restart your application often as when you\'re doing unt and integration tests. The other problem this causes with unit tests is that you need to create an application whenever you want to run a suite of tests. Although this is done through your testing framework (such as JUnit or TestNG), it means you don\'t have some of the features C# offers for unit testing such as running a single test or suite of tests easily, restarting only the failed tests and having all that tied to an external running engine which can run your tests in the background when you modify code.\\n\\n## Conventions\\nEverything I discussed above, plus all the documentation you find online and in code your colleagues wrote before you all force you into using conventions which I particularly dislike. Although some of these are also found in C#, I feel like Java forces you into them a lot more. I\'ll go over a couple of them here:\\n\\n### JavaBeans\\nThis is I think the biggest culprit for poor design in Java applications. You are forced to write data classes with essentially no domain logic within them. These objects must have getters for all properties and setters for most (if not all) of them as well. This creates immense boilerplate code for a lot of classes, making them unreadable pretty quickly. Since everything is public in these objects, it\'s pretty hard to actually enforce some domain separation. It also forces you to have an empty constructor so that engines can create these objects and set properties after, which means you can potentially create an object in an invalid state. These objects end up being usable as a simple object with public properties and no constructor, which goes against domain separation as in Domain Driven Design.\\n\\n### DAO\\nThe problem with this one is how people use it, yet again going against Domain Driven Design in favour of a layered architecture. In a typical domain repository, you would return domain objects for your services to use directly, but in DAOs, you usually return a database representation of your object, for your service to then translate into a domain object (adding translation logic which belongs to the repository inside your service). And then often it just translates it property for property into a JavaBean which doesn\'t add anything to it. All this works together to subtly force you into just using the DAO directly with the entities directly and never touch the services and Beans. If you then ever want to move your entities out of that monolith and into microservices let\'s say, you\'re going to have a hard time removing all the references to that DAO and entity and replacing them with the Beans wherever necessary.\\n\\n### Interfaces and implementations\\nAll too often, mostly because of the Spring dependency injection conventions, you end up having a single interface with a single implementation. The interface will have a valid name and then it\'s only implementation will just append `Impl` at the end. Even if you try to put the interface in a different package for access purposes, it\'s just useless since the implementation isn\'t really hidden. This usually breaks the purpose and ownership of interfaces. An interface belongs to the one using it and will have a name and method names that reflect that, the implementation will then probably have it\'s own language, but it won\'t be visible to the user of the interface. Java tends to revert this pattern and make generic interfaces with a single implementation, basically making it just a collection of classes talking to each other without the need for interfaces. I\'ve talked about this in previous posts, but if your only implementation for an interface has the same name, it\'s a smell that something isn\'t right. Chances are a lot of those methods aren\'t used outside of tests but you can\'t know that.\\n\\n## Code generation\\nSince Java is a very verbose language, and using conventions like JavaBeans forces you to write a lot of boilerplate code, a lot of code generation tools have surfaced to circumvent having to write so much code. The major library for this is Lombok. Although I love their annotations, especially for creating object builders, my biggest problem with these is that they often cause compilation problems because a modified class hasn\'t been regenerated yet or is using a cached version or something similar. This is especially noticeable when writing code in IDEs since they can\'t find a new property for your object until you compile which can become very cumbersome when you\'re modifying multiple different classes at the same time or are using TDD.\\n\\n## Conclusion\\nAs mentioned, the biggest problem with Java isn\'t the actual language, it\'s everything around it: JVM, Ant/Maven/Gradle, Spring, conventions and code generation. Java (and other JVM languages such as Kotlin, Scala and Clojure) offer a lot of nice features and ease of writting (especially with the newer version of Java) some good software. You just need to make sure you don\'t fall into the tools and conventions pitfalls.\\n\\nAs a funny addition, go check out the enterprise version of FizzBuzz, which presents a lot of the patterns I\'ve mentioned today: https://github.com/EnterpriseQualityCoding/FizzBuzzEnterpriseEdition."},{"id":"/2019/11/04/react","metadata":{"permalink":"/2019/11/04/react","source":"@site/blog/2019/11-04-react.md","title":"React + Redux + Saga","description":"After working a little with the React-Redux-Saga ecosystem, and working with others that were still new to it, I came to realize some parts of the frameworks can be a little confusing so I decided to write this post to explain how everything works together. This article isn\'t meant to explain everything, but give a brief overview of the different sections of the ecosystem and how they interact with each other in case you need to work on an existing project or need to think about which technology to use for new project.","date":"2019-11-04T00:00:00.000Z","formattedDate":"November 4, 2019","tags":[{"label":"Practices","permalink":"/tags/practices"},{"label":"Javascript","permalink":"/tags/javascript"}],"readingTime":9.925,"hasTruncateMarker":true,"authors":[],"frontMatter":{"title":"React + Redux + Saga","tags":["Practices","Javascript"]},"prevItem":{"title":"The problem with java isn\'t the language, it\'s the rest","permalink":"/2019/11/26/java"},"nextItem":{"title":"Indentation","permalink":"/2019/08/06/indentation"}},"content":"After working a little with the React-Redux-Saga ecosystem, and working with others that were still new to it, I came to realize some parts of the frameworks can be a little confusing so I decided to write this post to explain how everything works together. This article isn\'t meant to explain everything, but give a brief overview of the different sections of the ecosystem and how they interact with each other in case you need to work on an existing project or need to think about which technology to use for new project.\\n\\n\x3c!-- truncate --\x3e\\n\\n## React\\nReact is essentially a framework to easily divide your front-end application in different components which interact together to form your application. This helps separate concerns for the different parts of your application and reuse some of the components you create.\\n\\nYou define your components using either a class or a function syntax:\\n```javascript\\nclass Welcome extends React.Component {\\n    render() {\\n        return <h1>Hello, {this.props.name}</h1>;\\n    }\\n}\\n\\nfunction Welcome(props) {\\n    return <h1>Hello, {props.name}</h1>;\\n}\\n\\nfunction Welcome(props) => <h1>Hello, {props.name}</h1>;\\n```\\nAll these define a `Welcome` component that can be used inside other components with `<Welcome name=\\"myname\\"/>`. In the later version of React, function components can do anything a class component can, the only difference being the syntax.\\n\\n### Lifecycle\\nA big part of React\'s component is the lifecycle. It\'s important to understand what is available at which point in the lifecycle. New components follow four basic steps: \\n\\n1. constructor (for class components)\\n2. `render` function for class components or the function itself for function components\\n3. React updates the DOM\\n4. `componentDidMount` (for class components)\\n\\nThis means that React renders everything inside a temporary buffer before sending it to the DOM for the user to see and interact with. For most components, the `render` function is enough to handle everything needed. In cases where you want to do something when the page loads or is loaded, your best bet is the `componentDidMount` function. This ensures the component is properly mounted before you change anything inside it, as changes before mounting is done will not be visible.\\n\\nUpdating a component is triggered either by changing their properties, using the `setState` function inside the component or calling `forceUpdate` for your component. In this case, the component will follow these three steps:\\n\\n1. `render`\\n2. React updates the DOM\\n3. `componentDidUpdate`\\n\\nWhen unmounting a component, it will only call the `componentWillUnmount` if it is defined.\\n\\n### Properties\\nEvery component defines a set of properties that are used to customize it. Properties cannot be modified inside the component, they are simply there to change the behaviour of the component when it renders, or handles any action. You can define the properties you\'re expecting in your component as well as types for these properties by adding a propTypes property on your component class:\\n```javascript\\nimport PropTypes from \'prop-types\';\\n\\nWelcome.propTypes = {\\n    name: PropTypes.string\\n};\\n```\\nThe advantage of this is that most editors read these and help you with autocompletion and errors if you didn\'t add a required property or added an undefined property. You can also define defaults for the properties:\\n```javascript\\nWelcome.defaultProps = {\\n    name: \'stranger\'\\n};\\n```\\n\\n### Unit testing\\nUnit testing your components can be done with `enzyme`, a renderer for React components which let\'s you inspect the components to validate that they will be displayed correctly. Enzyme offers three rendering methods, all of which define a function taking your component as argument and returning a Renderer object containing methods to inspect the output:\\n#### Shallow Rendering\\n`shallow(node) => ShallowRenderer`\\nThis renders the component without rendering any child component. This means that the output of shallow will contain the tags specified by the used components and not their html representation. This is particularly useful when you want to unit test a component, and whether it correctly adds a child component or not.\\n#### Full DOM Rendering\\n`mount(node) => ReactWrapper`\\nThis renders the components and all its children. The output will contain valid html equivalent to what is being rendered to the user when using the application. This can be useful to test interactions with the DOM APIs. It requires a DOM, which is available in a browser or with the jsdom library. Since it is mounting the HTML in the DOM (similarly to how React actually works), you may need to use unmount between tests to clean your DOM so your tests don\'t impact each other.\\n#### Static Rendering\\n`render(node) => CheerioWrapper`\\nThis uses Cheerio, a library to render static HTML, to render the HTML statically for your component and its children. It only does rendering, it does not call React\'s component lifecycle and does not interact with the DOM. This is rarely used in practice since `shallow` and `mount` offer more without increasing testing time. \\n\\n## Redux\\nRedux is a library on top of React which adds a sharable state between the components as well as an event-driven architecture to help the components interact with each other.\\n### Actions\\nRedux lets you define actions which you can trigger manually whenever something happens. This is the publishing part of the event-driven architecture. Actions can also contain additional data. They are defined with the `createAction` function and triggered by calling the returned function:\\n```javascript\\n// define the action in a shared file\\nexport buttonPressed = createAction(\'BUTTON_PRESSED\');\\n// use the action in your component\\nbuttonPressed(additionalData);\\n```\\n### Reducers\\nReducers are functions triggered whenever a specific action is triggered. Their purpose is to update the global state depending on the triggered action and its additional data. They are created with the `handleAction` and `handleActions` functions with an initial state and a function mapping the received state to the new global state:\\n```javascript\\nhandleActions({\\n    BUTTON_PRESSED: (state) => ({ ...state, somethingElse: true }),\\n    OTHER_BUTTON_PRESSED: (state) => ({ somethingElse: false })\\n}, { somethingElse: false });\\n```\\n\\n### Connected Components\\nSince React updates the components only when their properties are changed, they will not be updated when the global state changes unless they are connected to the Redux engine. To connect your component, you need to define a `mapStateToProps` function that reads the new state and maps values from it to your components properties. You can also define a `mapDispatchToProps` object that will set some of your properties to actions you created previously (similarly to the `defaultProps` object). With all this, you then export a connected component instead of your previous component with the `connect` function:\\n```javascript\\nimport buttonPressed from \'./actions\';\\n\\nmapStateToProps = (state) => ({\\n    myProp: state.somethingElse\\n});\\n\\nmapDispatchToProps = {\\n    buttonPressed\\n};\\n\\nexport default connect(mapStateToProps, mapDispatchToProps)(Welcome);\\n```\\n### Event-driven architecture\\nAs mentioned, Redux uses an event-driven architecture style which will usually follow this lifecycle:\\n1. User interacts with your component\\n2. Component triggers an action\\n3. All reducers for that action will be called to modify the global state\\n4. mapStateToProps will be called on each component with the new global state\\n5. any component that changes a property during mapStateToProps will trigger it\'s update lifecycle and be updated\\n\\nThis helps to separate concerns inside your application. Actions are just placeholders to separate the different actions that can happen in your application. Reducers only need to know how to modify the state whenever a specific action is called. Components only need to know which action to trigger and their `mapStateToProps` only need to know what to do with the new state.\\n\\nIt also allows you to make modifications to other components from a component since all the reducers and `mapStateToProps` will be executed when an action is triggered.\\n\\nThe biggest thing to remember when using actions, reducers and connect components is that you want each action to be as simple as possible. This is why thinking in events is usually easier: text changed, button clicked, etc. Since the actions, reducers and state are global to your application, make sure to name them well and not reuse the same names for actions or state values.\\n\\n### Unit testing\\nActions cannot be unit tested as they are just definitions.\\n\\nReducers can easily be unit tested by ensuring the new state reflects the expected changes depending on the triggered action and additional information. The `handleActions` function returns a `reducer` function that takes an initial state and a object containing the type of triggered action (the string argument when you `createAction`) and the additional data as a payload. Executing this function returns the new state, making unit testing very simple:\\n```javascript\\nexpect(reducer({\\n    // empty initial state\\n}, {\\n    type: BUTTON_PRESSED,\\n    payload: { newValue: \'test\' }\\n})).toEqual({\\n    newValue: \'test\',\\n    somethingElse: true\\n});\\n```\\n\\nFor components, you will need to unit test the initial rendering (as before), the `mapStateToProps` function which is pretty straight forward and make sure that actions are correctly triggered when an action happens. This requires shallow or full DOM rendering (static rendering doesn\'t work).\\n```javascript\\ndefine(\'welcome\', () => {\\n    let component;\\n    const props = {\\n        buttonPressed: jest.fn(),\\n        name: \'test\'\\n    };\\n    \\n    beforeEach(() => {\\n        jest.clearAllMocks();\\n        component = shallow(<Welcome {...props}/>);    \\n    });\\n\\n    it(\'renders correctly\', () => {\\n        expect(component.find(\'something\').props().name).toEqual(props.name);    \\n    });\\n\\n    it(\'triggers action when button is pressed\', () => {\\n        component.find(\'button\').simulate(\'click\');\\n\\n        expect(props.buttonPressed).toHaveBeenCalledWith({ name: \'test\' });\\n    });\\n});\\n```\\n\\n## Saga\\nAs you probably guessed, some things are still a little complicated when using React with Redux, especially handling promises and such when calling apis to fetch data or make modifications. The React-Redux-Saga library helps greatly with this. Saga is a design pattern initially defined to handle interactions with multiple components you may or may not control. It is especially useful when your application must call multiple apis and revert each call if one of them failed.\\n\\nMost of the time when you need to fetch data with React-Redux, you\'ll end up with a call to an api that returns a promise. Once it resolves, you trigger the action associated with it. For simple cases like this, you may find Saga a little overwhelming, but for more complicated cases it greatly helps to reduce duplication and helps extract api logic from your components.\\n\\nIn React-Redux-Saga, you define generator functions that are executed when an action is triggered. They essentially act as a reducer with more logic.\\n```javascript\\nfunction* mySaga() {\\n    // execute when buttonPressed is triggered\\n    const additionalData = yield take(\'BUTTON_PRESSED\');\\n    // fetch some data\\n    const initialData = yield call(fetch(additionalData.id));\\n    // fetch some other data\\n    const moreData = yield call(fetchOther(initialData.something));\\n    // fetch some state value\\n    const stateData = yield select(state => state.somethingElse);\\n    // trigger an action with the fetched data\\n    yield put(dataFetched({ ...initialData, ...moreData, ...stateData }));\\n}\\n```\\n### Unit testing\\nThere are two methods to unit testing sagas. The first method goes through the generator function and expects the returns at each yield. This tightly couples your test code to your saga code, making any changes painful since you\'ll need to modify all the tests whenever you need to change the saga code.\\n```javascript\\nconst gen = mySaga();\\nexpect(gen.next()).toEqual(take(\'BUTTON_PRESSED\'));\\nexpect(gen.next({ id: \'id\' })).toEqual(fetch(\'id\'));\\nexpect(gen.next({ something: 2 })).toEqual(fetchOther(2));\\nexpect(gen.next({ blah: [] })).toEqual(select(state => state.somethingElse));\\nexpect(gen.next({ test: \'abc\' })).toEqual(put(dataFetched({ id: \'id\', something: 2, blah: [], test: \'abc\'})));\\nexpect(gen.next()).toEqual({ done: true, value: undefined });\\n```\\nThis can quickly become painful to maintain and debug if there is a problem.\\n\\nThe other method is to actually run the saga and expect the resulting dispatched actions.\\n```javascript\\nfetch = jest.fn().mockReturnValue({ something: 2 });\\nfetchOther = jest.fn().mockReturnValue({ blah: [] });\\n\\nconst dispatched = [];\\nconst saga = await runSaga({\\n    dispatch: (action) => dispatched.push(action),\\n    getState: () => ({ somethingElse: \'abc\' })\\n}, mySaga, {id:\'id\'}).toPromise();\\n\\nexpect(dispatched).toEqual([\\n    dataFetched({ id: \'id\', something: 2, blah: [], test: \'abc\' })\\n]);\\n```\\nSince you only expect the dispatch items to contain the desired actions and data, changing the saga code has less chances to break the tests unless the actual logic of the saga changes. With more complicated sagas, it becomes a much more powerful tool since you\'re actually testing the output of the function depending on the input and not the implementation."},{"id":"/2019/08/06/indentation","metadata":{"permalink":"/2019/08/06/indentation","source":"@site/blog/2019/08-06-indentation.md","title":"Indentation","description":"Over the years, many styles of indentation have surfaced. From K&R to Allman, Whitesmiths or GNU, using tabs vs spaces, there are a lot of choices. So how do you pick one?","date":"2019-08-06T00:00:00.000Z","formattedDate":"August 6, 2019","tags":[{"label":"Practices","permalink":"/tags/practices"},{"label":"Style","permalink":"/tags/style"}],"readingTime":4.435,"hasTruncateMarker":true,"authors":[],"frontMatter":{"title":"Indentation","tags":["Practices","Style"]},"prevItem":{"title":"React + Redux + Saga","permalink":"/2019/11/04/react"},"nextItem":{"title":"\\"Service\\" should be a banned word","permalink":"/2019/06/04/service"}},"content":"Over the years, many styles of indentation have surfaced. From K&R to Allman, Whitesmiths or GNU, using tabs vs spaces, there are a lot of choices. So how do you pick one?\\n\\nI will not advocate for a single style, but will give you guidelines on how to choose one that will last long and reduce the headaches that could be created with refactorings and such.\\n\\n\x3c!-- truncate --\x3e\\n\\n### Why tabs or spaces?\\nThis has been a long debate for which both sides have emitted a number of arguments. Arguments for using tabs often include:\\n- reduced disk space: since you\'re using 1 tab instead of multiple spaces, in the long run it can save disk space. This was a big problem in the early days of programming, but with the amount of disk space and memory we have today, it\'s pretty much been voided since then.\\n- allows user preference: if you prefer 4 spaces per tab and your colleague prefers 8 spaces per tab, you can each define the tab size and it should not interfere with each other. Take care to use a continuation style that allows for this (more on this further in the article).\\nOn the other side, for spaces the usual arguments are: \\n- universal standard: everybody sees the same code the same way.\\n- it allows for partial tabs: some like this, but as I will demonstrate shortly, this is an argument I don\'t agree with.\\n\\n### Continuation lines\\nOne of the main problems with indentation is continuation lines. Two main problems can arise if you align your arguments together. \\nFirstly, if you use tabs to indent (and probably spaces to fix the last part of the indentation, often refered to as smart tabs), different tab sizes will misalign the code:\\n```java\\n// with tab-size = 4, 3 tabs + 3 characters\\npublic int add(int a,\\n               int b) {\\n    return a + b;\\n}\\n// with tab-size = 8, 3 tabs + 3 characters\\npublic int add(int a,\\n                           int b) {\\n        return a + b;\\n}\\n```\\nThe first version may look good, but the second version is already harder to read, even with such a simple example.\\n\\nThe second problem that arises when renaming things, especially when you rename something on the line defining the size of the indentation. Let\'s see what happens to this code when you rename the function:\\n```java\\n// before rename\\npublic int addIntegers(int a,\\n                       int b) {\\n    return a + b;\\n}\\n// after rename\\npublic int add(int a,\\n                       int b) {\\n    return a + b;\\n}\\n```\\nAs you can see, this kind of continuation breaks easily when you rename a function, which probably happens a lot.\\n\\nBoth these problems can be fixed by choosing a continuation style that doesn\'t relate to previous lines. Here are some examples:\\n```java\\n// 1 tab worth\\npublic int add(int a,\\n    int b) {\\n    return a + b;\\n}\\n// 2 tabs worth\\npublic int add(int a,\\n        int b) {\\n    return a + b;\\n}\\n```\\nThe first example lowers readability a little bit, but there are options to reduce this problem.\\n\\n### Big blobs of code\\nLet\'s look at a more complicated function with multiple indentations and continuations:\\n```java\\npublic Reservation makeReservation(String restaurantName, \\n    DateTime time,\\n    int count) {\\n    Restaurant restaurant = restaurantService\\n        .getRestaurantByName(restaurantName);\\n    if (restaurant.isOpen() &&\\n        restaurant.reservationCount(time) + count < restaurant.capacity()) {\\n        Reservation reservation = restaurant.makeReservation(time, count);\\n        restaurantService.saveRestaurant(restaurant);\\n        return reservation;\\n    }\\n    return null;\\n}\\n```\\nThis is already hard to read even though there are less than 10 lines of code. Here are some tips if you encounter this kind of code a lot: \\n- use a bigger size for continuation lines: here the continuation lines are on the same indentation level as the code inside the block. It\'s hard to determine what\'s the continuation and what\'s the block. Using 2 tabs for continuation lines will mark a difference between the continuation and the block.\\n- add white lines/brace lines: whether you place your opening braces on the following line or use a white line to separate the continuations from the blocks it helps a lot to separate continuation from block.\\n- refactor some of it, combine shorter lines, extract functions: extracting multiple parts of code to functions is always a good idea to increase readability. Inverting conditionals often reduces complex reading also.\\n\\nWith these tips in mind, here is the same example:\\n```java\\npublic Reservation makeReservation(String restaurantName,\\n        DateTime time,\\n        int count)\\n{\\n    Restaurant restaurant = restaurantService.getRestaurantByName(restaurantName);\\n    if (reservationCannotBeMade(restaurant, time, count))\\n        return null;\\n\\n    Reservation reservation = restaurant.makeReservation(time, count);\\n    restaurantService.saveRestaurant(restaurant);\\n    return reservation;\\n}\\n\\nprivate boolean reservationCannotBeMade(Restaurant restaurant, DateTime time, int count) \\n{\\n    return restaurant.isClosed() ||\\n            restaurant.reservationCount(time) + count > restaurant.capacity();\\n}\\n```\\n\\n### Working in a team\\nAs I\'ve stated in the past, if you\'re working in a team, the whole team should decide the style together and set it in their editors so that it\'s standard for everybody and you don\'t have unnecessary modified lines in code reviews. A great place to put these settings is in the .editorconfig file of your project. This file is read by most of the major editors, IDEs and even websites like Github and Bitbucket. Having the indentation style specified in this file helps to make the code in your Github code reviews the same as in your IDE."},{"id":"/2019/06/04/service","metadata":{"permalink":"/2019/06/04/service","source":"@site/blog/2019/06-04-service.md","title":"\\"Service\\" should be a banned word","description":"Just like \\"Manager\\" or \\"Data\\", I think \\"Service\\" is another word we should ban from our code. When you read Domain Driven Design theory, services are there to help you correctly separate concerns and contain some domain logic while handling other domain objects. Although services are an integral part of DDD, it\'s not a design pattern so you shouldn\'t have a class name containing \\"Service\\".","date":"2019-06-04T00:00:00.000Z","formattedDate":"June 4, 2019","tags":[{"label":"Practices","permalink":"/tags/practices"}],"readingTime":3.805,"hasTruncateMarker":true,"authors":[],"frontMatter":{"title":"\\"Service\\" should be a banned word","tags":["Practices"]},"prevItem":{"title":"Indentation","permalink":"/2019/08/06/indentation"},"nextItem":{"title":"CrudRepository is an anti-pattern","permalink":"/2019/05/22/crudrepository"}},"content":"Just like \\"Manager\\" or \\"Data\\", I think \\"Service\\" is another word we should ban from our code. When you read Domain Driven Design theory, services are there to help you correctly separate concerns and contain some domain logic while handling other domain objects. Although services are an integral part of DDD, it\'s not a design pattern so you shouldn\'t have a class name containing \\"Service\\".\\n\\n\x3c!-- truncate --\x3e\\n\\n### It leads to unmaintainable code\\nWe have an expression in french to describe something that contains everything: \\"fourre-tout\\", literally fill-everything. This describes exactly what happens when you have a class whose name contains \\"Service\\".\\n\\nLet\'s say you\'re working on a marketplace application, at some point you\'ll probably have a cart to which you can add items. Your first reflex is probably to create a CartService which will handle everything pertaining to the cart. You can create a new cart, add an item to your cart, remove an item from you cart, change the quantity of an item in your cart, process that cart, delete that cart, etc. Already we\'re seeing six methods. If we average each method to 10 lines or so (including private functions needed for each main function), that\'s already 60 lines. Add the imports and other obligatory information, you\'re probably close to 100 lines. Now go back to those six methods: each method now counts as 10 percent of the file overall. If you\'re looking for an information in that class, 90 percent of the file is probably useless to you. Every time you add a new feature, you\'ll have to ask yourself \\"where do a put this new method?\\".\\n\\nNow look at the tests for this class. Six methods each with around five unit tests: that\'s 30 unit tests, probably all in the same file name \\"CartServiceTest\\". That\'s beginning to be a lot harder to manage.\\n\\nIf you\'re also using the repository pattern incorrectly (see my [previous post]({% post_url 2019/2019-05-22-crudrepository %})), you\'re probably also adding methods in this service to translate between your domain cart and your database cart and call the appropriate method of your repository. All these methods will probably have a test or two also. This CartService is rapidly getting to an unmaintainable size. Same goes for the CartServiceTest.\\n\\nAnother problem arrising from large files containing everything is merging problems when working with multiple people. Two stories can easily force you to work on the same huge class although they\'re in different features. If two people take one story each, there\'s bound to be some merging to do at some point.\\n\\n### How do you fix this?\\n\\n#### Make use of the repository pattern correctly\\nIt should receive and return domain objects. This allows it to be used directly within your domain, reducing the need for translation methods in your services. If you don\'t have translation methods in your domain, you also don\'t have tests for these translation methods in your domain, reducing \\"gravy\\" methods and concentrating the domain on the important stuff.\\n\\n#### Think Single Responsibility Principle\\nEach class should have one responsibility and it should do it well. Separate all those methods into different classes and name these classes according to what they do. Remember that every class should be a noun and every method should be a verb. Going back to the cart example, you could have CartCreator.Create, CartItemAdder.Add, CartItemRemover.Remove, etc. Also separate your test file into different tests for each feature.\\n\\n### How does this fix things?\\nEach new class has only one responsibility, it\'s not crowded with methods not pertaining to that responsibility, and the tests associated are also separated so it\'s easy to see all the business rules associated with a feature: they\'re all in a single code file and a single test file. If you find that your class is becomming too large because it\'s particular feature has a lot of business rules, nothing stops you from extracting these into a separate class, or grouping common rules between multiple features into a shared class. At least each fonctionality has a single starting point, so it\'s still easy to navigate to it.\\n\\nAs you start adding more and more features in the long term, it\'s also easier to know where to add a new feature (just create a new file) or where to find an existing feature (having a good folder structure helps, but most editors can easily find a file within your whole project in an instant).\\n\\nAs a bonus, you\'re also removing the merging problem arrising from two people working on different features at the same time."},{"id":"/2019/05/22/crudrepository","metadata":{"permalink":"/2019/05/22/crudrepository","source":"@site/blog/2019/05-22-crudrepository.md","title":"CrudRepository is an anti-pattern","description":"CrudRepositories may seem like a nice way to boost productivity, but I think they lead to bad design and I\'ll explain why.","date":"2019-05-22T00:00:00.000Z","formattedDate":"May 22, 2019","tags":[{"label":"Practices","permalink":"/tags/practices"}],"readingTime":5.255,"hasTruncateMarker":true,"authors":[],"frontMatter":{"title":"CrudRepository is an anti-pattern","tags":["Practices"]},"prevItem":{"title":"\\"Service\\" should be a banned word","permalink":"/2019/06/04/service"},"nextItem":{"title":"Book Review: Growing Object-Oriented Software, Guided by Tests","permalink":"/2019/04/16/growing-object-oriented-software-guided-by-tests"}},"content":"CrudRepositories may seem like a nice way to boost productivity, but I think they lead to bad design and I\'ll explain why.\\n\\n\x3c!-- truncate --\x3e\\n\\n### First off, what is a CrudRepository?\\nIn Domain Driven Design, a repository is an object used to access persisted information, usually in a database. It provides methods for accessing certain objects and modifying them. CRUD is the smallest set of methods that can be used to work with your data. It consists of four explicitly named methods: Create, Read, Update, Delete. A CrudRepository is a class implementing these four methods. These are usually generic, and sometimes even automatically generated (see Spring). They usually look something like this:\\n```java\\npublic class CrudRepository<T> {\\n   public int create(T t) {...}\\n   public T read(int id) {...}\\n   public void update(T t) {...}\\n   public void delete(T t) {...}\\n}\\n```\\n\\n### It leads to layered architecture\\nSo the first problem I see with this is that it will usually lead to a layered architecture in the sense that your domain objects will now depend on database objects. The class your passing to this CrudRepository will contain information that pertains to the database, either through annotations or by the class being a direct mapping of a specific table. One of two things will usually happen once you start using this pattern: \\n1. You might use domain objects, but your domain services will have to translate those into database objects and vice-versa to use the repository. This adds an extra responsibility to your domain services, making them harder to read.\\n2. You will simply use those database objects everywhere in your application, forcing your to write your services to contain all the domain logic and not having domain objects that contain their specific logic.\\n\\nAnother big point to note with layered architecture is that whenever you change your database schema, you will likely have to change bits and pieces in all of your code. This will become harder and harder going further and take more and more time to complete.\\n\\nDomain Driven Design encourages a clean separation between your domain objects and your database to reduce this problem. You should have a repository interface that resides within your domain and uses domain objects and the implementation should handle the translation between the domain objects and the database objects. A database change will then only affect your database objects and implementation of the repositories, but nothing else.\\n\\n### How can you fix this?\\nAs mentioned earlier, you should have a repository interface inside your domain that uses domain objects. Something like this:\\n```java\\npublic interface EmployeeRepository {\\n    public Employee createNewEmployee(String firstName, String lastName, String email, ...);\\n    public Employee getEmployeeById(int id);\\n    public Employee getEmployeeByEmail(String email);\\n    public void saveEmployee(Employee employee);\\n    public void deleteEmployee(Employee employee);\\n}\\n```\\n\\nYour implementation will then have to translate between your domain objects (Employee in this case) and your database objects. This class can use the CrudRepository if you want to:\\n```java\\npublic class SqlEmployeeRepository : EmployeeRepository {\\n    private CrudRepository<DbEmployee> crud;\\n    \\n    public Employee createNewEmployee(String firstName, String lastName, String email, ...) {\\n        Employee employee = new Employee(firstName, lastName, email);\\n        DbEmployee dbEmployee = new DbEmployee(employee);\\n        employee.id = crud.create(dbEmployee);\\n        return employee;\\n    }\\n    \\n    public getEmployeeById(int id) {\\n        return crud.read(id).toEmployee();\\n    }\\n    \\n    public void saveEmployee(Employee employee) {\\n        crud.update(new DbEmployee(employee));\\n    }\\n    \\n    public void deleteEmployee(Employee employee) {\\n        crud.delete(new DbEmployee(employee))\\n    }\\n    \\n    ...\\n}\\n```\\n\\nNow, whenever you change the database schema, you only need to change the database object (DbEmployee) and the implementation of the repository (SqlEmployeeRepository). If your domain doesn\'t need this added information, you can just ignore it. This is especially useful when working with a database that may be used by other application within your company. You probably don\'t care about half of the information in the database, so why force yourself to map it exactly? Create domain objects that contain just the information you need for your application and let the repository and database objects extract the pertinent information from the database.\\n\\nHaving the translation between the domain objects and the database objects in the repository also simplifies your domain services, making it easier to add new features or modify existing ones, and reducing the risk of errors in these objects.\\n\\n### So why move away from crud repositories if you must work more?\\nYou\'ll more easily separate your different logic types between each layer of your application and it\'ll be easier to make modifications and understand your domain objects and services with this in mind in the long term.\\nTake for example these two version of the same employee hiring method of a domain service:\\n```java\\npublic EmployeeService {\\n    private CrudRepository<EmployeeEntity> repository;\\n    private EmployeeEmailService emailService;\\n    \\n    public EmployeeBean hireEmployee(String firstName, String lastName) {\\n        String email = emailService.generateEmailForNewEmployee(firstName, lastName);\\n        EmployeeEntity entity = new EmployeeEntity(firstName, lastName, email);\\n        entity.id = repository.create(entity);\\n        return new EmployeeBean.Builder()\\n            .id(entity.id)\\n            .firstName(entity.firstName)\\n            .lastName(entity.lastName)\\n            .email(entity.email);\\n    }\\n}\\n```\\n\\n```java\\npublic EmployeeService {\\n    private EmployeeRepository repository;\\n    private EmployeeEmailService emailService;\\n    \\n    public Employee hireEmployee(String firstName, String lastName) {\\n        String email = emailService.generateEmailForNewEmployee(firstName, lastName);\\n        return repository.createNewEmployee(firstName, lastName, email);\\n    }\\n}\\n```\\n\\nIn the first instance, using a crud repository, you get polluted with translation between different object types representing the same concept (an employee). Only two of the eight lines are pertinent and they\'re lost in the translation. For the second example, the two same lines doing application logic are the only two lines and it\'s a lot easier to read this way.\\n\\nAnother clear advantage is when you unit test these methods. The first example will force you to compare the EmployeeBean object your method return with the EmployeeEntity your mocked repository\'s method returned. If you then add a new field to your EmployeeBean or EmployeeEntity, you might miss this translation, but your test will still pass, probably breaking something down the line. In the second example, if you make your repository return an object and directly compare it to the object returned by the method, there\'s no way your comparison will fail, and if there are ever changes to your database schemas or domain objects, this code will still function correctly because it doesn\'t contain the translation.\\n\\n### Conclusion\\nRemember that an interface belongs to it\'s user, not it\'s implementer. Since the user of the repository is the service, the repository\'s interface belongs to the service and should talk in terms of domain objects, simplifying the service using it."},{"id":"/2019/04/16/growing-object-oriented-software-guided-by-tests","metadata":{"permalink":"/2019/04/16/growing-object-oriented-software-guided-by-tests","source":"@site/blog/2019/04-16-growing-object-oriented-software-guided-by-tests.md","title":"Book Review: Growing Object-Oriented Software, Guided by Tests","description":"Today I\'ll be doing a review of the book \\"Growing Object-Oriented Software, Guided by Tests\\" by Steve Freeman and Nat Pryce.","date":"2019-04-16T00:00:00.000Z","formattedDate":"April 16, 2019","tags":[{"label":"Review","permalink":"/tags/review"}],"readingTime":2.59,"hasTruncateMarker":true,"authors":[],"frontMatter":{"title":"Book Review: Growing Object-Oriented Software, Guided by Tests","tags":["Review"]},"prevItem":{"title":"CrudRepository is an anti-pattern","permalink":"/2019/05/22/crudrepository"},"nextItem":{"title":"New stuff in C#8: Nullable Reference Types","permalink":"/2019/03/19/cs8-nullable-reference-types"}},"content":"Today I\'ll be doing a review of the book \\"Growing Object-Oriented Software, Guided by Tests\\" by Steve Freeman and Nat Pryce.\\n\\nMost people are aware of the TDD cycle of Fail - Pass - Refactor, this book uses this concept at a bigger level by doing acceptance tests with this cycle, which drives smaller cycles for integration and unit tests. It has a very good example solution which helps to understand how everything fits together on a larger scale.\\n\\n\x3c!-- truncate --\x3e\\n\\n### Who is this book for?\\nPeople who already have a basic understanding of Test Driven Development might find a new possibility in writing acceptance tests that drive all the tests and code. The book also briefly explains the basic concepts of Test Driven Development, so people who aren\'t used to TDD can pick it up too.\\n\\n### What should be read in this book?\\nI think that this book should be read from cover to cover. The basic concepts at the start of the book are very theoretical but well explained and the example given after helps cement your understand.\\n\\n### What should be retained from this book?\\nAll the basic concepts of Acceptance Test Driven Development and the larger test cycle. There is whoever a small section at the beginning of the example which I would not recommend retaining: the walking skeleton.\\n\\nThe walking skeleton is a technique he uses to start a new project and consists of writing a test that will force you to implement a basic continuous integration and testing platform. However these days with the advent of platforms that handle a big part of it for you like Bitbucket\'s pipelines or Microsoft\'s Azure DevOps (formerly VSTS), this practice isn\'t as necessary as it may once have been (the book was written in 2009, the tools came out around 2017). The reason being that these tools allow you to quickly start a new project with continuous integration already built in with a simple button click.\\n\\nI do however encourage starting your project with a simple test that just starts up the application and ensures that your testing libraries can interract with it.\\n\\n### How does this apply to proper code?\\nTest Driven Development is a core concept of proper coding techniques that helps you ensure that the functionality is working, decouple your objects and write maintainable code. Doing Acceptance Test Driven Development makes it easier to integrate automated acceptance tests in your development cycle as you write these first. It also ensures that you don\'t forget a part of the code needed to implement the new feature. When using Git Flow for managing branches, it\'s especially powerful as the first thing you do in your new branch will be an acceptance test, and your branch is ready to merge when that acceptance test passes. It should also be noted that this pattern can also be used when fixing bugs by writing a test that follows the expected behaviour of the program (which should fail because there\'s a bug) and adding tests and code until that test passes (essentially fixing the bug)."},{"id":"/2019/03/19/cs8-nullable-reference-types","metadata":{"permalink":"/2019/03/19/cs8-nullable-reference-types","source":"@site/blog/2019/03-19-cs8-nullable-reference-types.md","title":"New stuff in C#8: Nullable Reference Types","description":"Today I\'m starting a small series on new features coming to C#8.0, starting with Nullable Reference Types.","date":"2019-03-19T00:00:00.000Z","formattedDate":"March 19, 2019","tags":[{"label":"Technologies","permalink":"/tags/technologies"},{"label":"C#","permalink":"/tags/c"}],"readingTime":2.28,"hasTruncateMarker":true,"authors":[],"frontMatter":{"title":"New stuff in C#8: Nullable Reference Types","tags":["Technologies","C#"]},"prevItem":{"title":"Book Review: Growing Object-Oriented Software, Guided by Tests","permalink":"/2019/04/16/growing-object-oriented-software-guided-by-tests"},"nextItem":{"title":"Jekyll, pagination, categorizing and Javascript","permalink":"/2019/03/03/jekyll-javascript"}},"content":"Today I\'m starting a small series on new features coming to C#8.0, starting with Nullable Reference Types.\\n\\n\x3c!-- truncate --\x3e\\n\\nC# has a type system, like many other languages, which allows you to assign null to any non-primitive object (pretty much everything except integers, floating point numbers and characters). This means that whenever you receive a reference type through a function parameter or keep one as an instance variable, you need to make sure that it\'s not null before using it (or deal with the NullReferenceException). This also meant that you couldn\'t have nullable reference types (ex: `string?` or `Person?`).\\n\\nOne of the new features coming is a compilation flag you can add to your project to make reference types require non-null values, while also allowing to create nullable reference types. This explicits the fact that your variable or parameter may be null and it\'s ok because you handle it.\\n\\nThe only downside right now in the preview is that it is not enforced at compilation time, it only shows a warning when you\'re not initializing a non-nullable reference type or when you use it:\\n\\n```C#\\nclass Person {\\n    private string firstName; // non-nullable string\\n    public string LastName { get; set; }\\n    \\n    public Person() {\\n        // this constructor has the following warnings:\\n        // Non-nullable field \'firstName\' is uninitialized.\\n        // Non-nullable property \'LastName\' is uninitialized.\\n        \\n        // this should idealy not compile or initialize the field and property with default values\\n    }\\n    \\n    public Person(Person copy) {\\n        firstName = copy.firstName;\\n        LastName = copy.LastName;\\n    }\\n    \\n    public string FirstName() => firstName;\\n}\\n```\\n\\n```C#\\n[TestClass]\\nclass PersonTest {\\n    [TestMethod]\\n    public void CreatesPersonFromNothing() {\\n        var person = new Person();\\n        // both of these assertions will pass (although the field and property shouldn\'t be null) \\n        // and show the following warnings:\\n        // Cannot convert null literal to non-nullable reference or unconstrained type parameter.\\n        Assert.AreEqual(null, person.FirstName());\\n        Assert.AreEqual(null, person.LastName);\\n        // this should fail because the field and property can\'t be null\\n    }\\n    \\n    [TestMethod]\\n    public void ThrowsExceptionWhenCreatingPersonFromNull() {\\n        // this will show the warning: \\n        // Cannot convert null literal to non-nullable reference or unconstrained type parameter.\\n        Assert.ThrowsException<NullReferenceException>(() => new Person(null));\\n        // this shouldn\'t compile because you\'re passing null to a non-nullable reference type\\n    }\\n}\\n```\\n\\nSo all in all, I like this addition but would prefer having compilation errors and default initializations (empty string or parameter-less constructor). This would make sure you always have a value, either by initializing it for you in the case of fields and properties or by forcing you to pass a non-null value as a function parameter. Having the compilation flag means that we won\'t be coding defensively (making sure objects aren\'t null before using them), so we need a way to ensure our object isn\'t null at compilation time."},{"id":"/2019/03/03/jekyll-javascript","metadata":{"permalink":"/2019/03/03/jekyll-javascript","source":"@site/blog/2019/03-03-jekyll-javascript.md","title":"Jekyll, pagination, categorizing and Javascript","description":"As some of you may know Jekyll is an application to build static websites. It\'s used by GitHub-Pages (where this blog is residing). One of the disadvantages of having a static website is that every page must be created before publishing it. This means that you cannot do filtering based on query parameters and such, and all the sub-pages for pagination must be generated before hand. Jekyll does allow extensions in Ruby to generate the pages, one of which is a paginator, but for some reason I\'ve had trouble making it work on GitHub-Pages. The paginator also doesn\'t work with multiple languages like this blog.","date":"2019-03-03T00:00:00.000Z","formattedDate":"March 3, 2019","tags":[{"label":"Blog","permalink":"/tags/blog"},{"label":"Update","permalink":"/tags/update"}],"readingTime":2.335,"hasTruncateMarker":true,"authors":[],"frontMatter":{"title":"Jekyll, pagination, categorizing and Javascript","tags":["Blog","Update"]},"prevItem":{"title":"New stuff in C#8: Nullable Reference Types","permalink":"/2019/03/19/cs8-nullable-reference-types"},"nextItem":{"title":"WSL (or why I won\'t make Linux VMs in Windows)","permalink":"/2019/02/21/wsl"}},"content":"As some of you may know Jekyll is an application to build static websites. It\'s used by GitHub-Pages (where this blog is residing). One of the disadvantages of having a static website is that every page must be created before publishing it. This means that you cannot do filtering based on query parameters and such, and all the sub-pages for pagination must be generated before hand. Jekyll does allow extensions in Ruby to generate the pages, one of which is a paginator, but for some reason I\'ve had trouble making it work on GitHub-Pages. The paginator also doesn\'t work with multiple languages like this blog.\\n\\n\x3c!-- truncate --\x3e\\n\\nAfter trying all this for a while, I decided to go the old route and add a bit of Javascript to my pages to add pagination and categorizing. I used ES6 Javascript with no additional libraries (like JQuery).\\n\\n### Categorizing\\n\\nCategorizing has been achieved by removing posts from the list if they don\'t fit the currently selected. I added a query parameter to the Posts by category links on the left of the page and retrieve it with the following Javascript code:\\n\\n```javascript\\nconst categories = window.location.search.substr(1).split(\'&\').map(v => v.split(\'=\'));\\nreturn new Map(categories).get(\'category\');\\n```\\n\\nFiltering is then accomplished with this bit of code:\\n\\n```javascript\\nlet postList = document.querySelector(\'ul.post-list\');\\ndocument.querySelectorAll(\'ul.post-list li\')\\n    .forEach(post => post.dataset.category !== category && postList.removeChild(post));\\n```\\n\\n### Pagination\\n\\nOnce this is done I add pagination by creating `li` and `button` elements in an empty `ul` already in the page. Page selection is then accomplished by hiding the posts from other pages while showing the posts from the current page.\\n\\n```javascript\\nclass Paginator {\\n    constructor(pageSize) {\\n        this.pageSize = pageSize;\\n        this.posts = document.querySelectorAll(\'ul.post-list li\');\\n        this.pageCount = Math.ceil(this.posts.length / this.pageSize);\\n    }\\n\\n    paginate() {\\n        if (this.posts.length === 0) return;\\n        this.addPagination();\\n        this.selectPage(1);\\n    }\\n\\n    addPagination() {\\n        const pageListElement = document.querySelector(\'ul.page-list\');\\n        for (let i = 1; i <= this.pageCount; ++i) {\\n            let pageElement = document.createElement(\'li\');\\n            let pageAnchor = document.createElement(\'button\');\\n            pageAnchor.addEventListener(\'click\', () => this.selectPage(i));\\n            pageAnchor.innerText = i.toString();\\n            pageElement.appendChild(pageAnchor);\\n            pageListElement.appendChild(pageElement);\\n        }\\n        this.pages = document.querySelectorAll(\'ul.page-list li\');\\n    }\\n\\n    selectPage(page) {\\n        for (let i = 1; i <= this.pages.length; ++i) {\\n            if (i === page)\\n                this.pages[i-1].classList.add(\'current-page\');\\n            else\\n                this.pages[i-1].classList.remove(\'current-page\');\\n        }\\n        for (let i = 1; i <= this.posts.length; ++i) {\\n            if (Math.ceil(i / this.pageSize) === page)\\n                this.posts[i-1].removeAttribute(\'hidden\');\\n            else\\n                this.posts[i-1].setAttribute(\'hidden\', true);\\n        }\\n    }\\n}\\n```\\n\\n### Disclaimer\\n\\nI am aware this will not work in older browsers or with Javascript disabled, but I\'m guessing people that read this blog will be using a recent browser anyway. Not running the Javascript on the index page will simply mean that categorizing and pagination will not work, but the actual website will still continue working as it should.\\n\\n### So what\'s left after this update?\\n\\nFixing dates so they show according to the language (which seems to require a lot of code). More CSS everywhere."},{"id":"/2019/02/21/wsl","metadata":{"permalink":"/2019/02/21/wsl","source":"@site/blog/2019/02-21-wsl.md","title":"WSL (or why I won\'t make Linux VMs in Windows)","description":"Windows Subsystem for Linux (WSL) has been out for a couple of years now and many people have put in a lot of work to make it even better. It all started with the Bash on Ubuntu on Windows, but has since evolved to accept different distributions (there are a couple available in the Microsoft Store and you can install some yourself). It has been improved to the point that I don\'t see the point in running a Linux VM in Windows (unless you want other utilities of VMs such as copying the whole system or such).","date":"2019-02-21T00:00:00.000Z","formattedDate":"February 21, 2019","tags":[{"label":"Technologies","permalink":"/tags/technologies"},{"label":"WSL","permalink":"/tags/wsl"}],"readingTime":4.755,"hasTruncateMarker":true,"authors":[],"frontMatter":{"title":"WSL (or why I won\'t make Linux VMs in Windows)","tags":["Technologies","WSL"]},"prevItem":{"title":"Jekyll, pagination, categorizing and Javascript","permalink":"/2019/03/03/jekyll-javascript"},"nextItem":{"title":"Book Review: Agile Principles, Patterns, and Practices in C#","permalink":"/2019/02/12/agile-principles-patterns-practices"}},"content":"Windows Subsystem for Linux (WSL) has been out for a couple of years now and many people have put in a lot of work to make it even better. It all started with the Bash on Ubuntu on Windows, but has since evolved to accept different distributions (there are a couple available in the Microsoft Store and you can install some yourself). It has been improved to the point that I don\'t see the point in running a Linux VM in Windows (unless you want other utilities of VMs such as copying the whole system or such).\\n\\n\x3c!-- truncate --\x3e\\n\\n### What exactly is WSL\\nThe Windows Subsystem for Linux is actually a recompiled Linux kernel that runs on top of Windows. You can now install multiple different distributions of Linux along side one another and switch between them (since Windows update 1809 in October 2018) using their wsl executable.\\n\\n### How I started using WSL\\nNot long after I started university I switched to using Linux as my main work operating system (although I still kept a Windows partition/computer for games and such). I find myself much more productive using a linux shell than Windows\' cmd or PowerShell. The tools are also much more powerful and can offer a lot more utility. The companies I worked at were using Windows and developing applications for Windows so I didn\'t have a choice to use that as my main work environment, but I always tried to use some Linux knowledge and tools when working. It started with Cygwin and that lasted for a while until Ubuntu on Windows came out. Although WSL\'s first versions were sometimes buggy and didn\'t allow much, it was still an improvement and now I\'m very happy with the environment I set up. \\n\\n### What I like about WSL\\nThe integration between Linux and Windows is very well made. The fact that you\'re actually running a Linux kernel inside of Windows means that you\'ll be able to run any application with currently runs on Linux natively without needing to recompile them or run them in a virtual machine. You\'re not limited to a certain amount of threads/processor usage/memory/disk space as you would with a virtual machine either so you can run very demanding programs without running any problems. The fact that you aren\'t booting a computer also means that starting a new instance is practically instantaneous. You can also run any distribution you want and get the tailored tools they offer.\\n\\n### How I set up my WSL\\nI won\'t explain how to set up the default WSL tools, there are many guides for those. I will however explain what I did after that.\\n\\nWhen you first activate WSL, it comes with an Ubuntu installation as the default distribution, but you can install other distribution from the Microsoft Store or install you\'re own distribution with the WSL api that Windows provides. The only problem is that the function isn\'t easily available so you need to access it with some [code](https://github.com/lavoiecsh/lavoiecsh.github.io/blob/master/code/other/WSLInstaller.c) which you need to compile and execute passing in the distribution name you want to set for wsl and the filename of a distribution installation media compressed in tar.gz format. I used this to install a stage3 version of Gentoo, which is my favourite distribution so far. For those that want to use Gentoo, simply follow the [handbook](https://wiki.gentoo.org/wiki/Handbook:AMD64) starting with MAKEOPTS and portage set up (Skip the chrooting and kernel parts).\\n\\nAlthough I\'m using tmux, I like using ConEmu to launch the distribution once I have it set up because I usually just leave it open and can add tabs for other prompts (cmd, powershell) whenever I need. The ConEmu task is set to run `wsl.exe -d gentoo -u lavoiecsh`. The only problem with the Windows console (and ConEmu) is that some of the keybindings are broken (Ctrl-Space, Ctrl-Backspace), so I\'ve decided to run my emacs using X (more on that shortly).\\n\\nAnother tool I installed is VcXsrv. This is a Visual C compiled version of the X server for Linux. It runs inside Windows and creates a display that graphical applications in Linux can use to display themselves. Once you\'ve installed it, run the XLaunch.exe tool in the default folder and select Multiple Applications. Save the configuration at the end of the XLaunch wizard and create a link to it in your start up folder (`%APPDATA%\\\\Microsoft\\\\Windows\\\\Start Menu\\\\Programs\\\\Start-up`) so that it will launch when you start Windows. This will create a display (`:0.0` by default) that your linux applications can use. Once XLaunch is running (it only displays an icon in the launch bar), when you launch a graphical application in Linux it will start it in a new window.\\n\\nWith VcXsrv installed and running, I usually start emacs to get a windowed server running (by adding `(server-start)` in my initialization file). After that, whenever I need to edit a file, I can look it up with emacs, or run `emacsclient -nqu <filename>` (aliased to `em` in my case) to send it to the emacs server from the console.\\n\\nI chose not to run a full graphical interface (window manager or desktop manager) since I barely use graphical tools with linux and I find that having WSL running inside ConEmu with tmux gives me all the bash prompts I need and having emacs running with VcXsrv gives me all the edition tools I need (while also circumventing the keybinding problems that the Windows console has). \\n\\n### Conclusion\\nWSL is now very powerful, especially when combined with tools such as ConEmu and VcXsrv. I am confident that I will be using it for a while and that more developments will continue on it in the next couple of years."},{"id":"/2019/02/12/agile-principles-patterns-practices","metadata":{"permalink":"/2019/02/12/agile-principles-patterns-practices","source":"@site/blog/2019/02-12-agile-principles-patterns-practices.md","title":"Book Review: Agile Principles, Patterns, and Practices in C#","description":"This is the first book I have read since university. It was proposed to me not long after I joined the company I currently work at and is one of the inspirations for the way I work and this blog.","date":"2019-02-12T00:00:00.000Z","formattedDate":"February 12, 2019","tags":[{"label":"Review","permalink":"/tags/review"}],"readingTime":3.19,"hasTruncateMarker":true,"authors":[],"frontMatter":{"title":"Book Review: Agile Principles, Patterns, and Practices in C#","tags":["Review"]},"prevItem":{"title":"WSL (or why I won\'t make Linux VMs in Windows)","permalink":"/2019/02/21/wsl"},"nextItem":{"title":"Importance of Good Tools","permalink":"/2019/01/28/tools"}},"content":"This is the first book I have read since university. It was proposed to me not long after I joined the company I currently work at and is one of the inspirations for the way I work and this blog.\\n\\nI\'m going to talk about the C# version of the book (Agile Principles, Patterns, and Practices in C#), but it also applies to the Java version (Agile Software Development: Principles, Patterns, and Practices). Both books were written by Robert C. Martin (Uncle Bob).\\n\\n\x3c!-- truncate --\x3e\\n\\n### Who is this book for?\\nThis book is for every new developer especially those wanting to work with object oriented languages, as long as they have the fundamentals of program flow (functions, loops, conditions, etc). Most of the concepts are general and will be used in any programming paradigm, but the examples use an OO language (either C# or Java). \\n\\nI\'ve read this book after starting my second job, 5 years after having finished my bachelor\'s degree, 3 years after starting to work in the domain, and wished I could have read it as I was finishing my degree, or right after. The concepts greatly help you in every aspects of programming.\\n\\n### What should be read in this book?\\nI think you should read everything in the book. The book flows pretty well and is written in a simple language so it\'s easy and fast to read. Here are the main sections of the book:\\n1. Introduction to Agile Programming principles and Extreme Programming, including testing and refactoring: this is something we hear about at school, but don\'t get to practice.\\n2. SOLID principles: these are very important not only to OO programming, but programming in general. The concepts are simple but greatly help clarify your code and make it more maintainable.\\n3. UML and other diagrams: you probably learned these and school and thought you\'ll never touch it again, especially not to write up analysis documents. One thing he mentions that you should remember are that they help to communicate with other developers. Most of the diagrams I do are on white-board so that they can be easily modified. They aren\'t perfect UML by any means, but they convey the information you need to have conveyed. And if you need to save it somewhere, just snap a photo once you\'re done.\\n4. Case studies and design patterns: the last and largest part of the book is a presentation of different example, mainly one case study, which is intertwined with some design pattern theory. The examples introduce problems which are solved by the design patterns which are presented, so it\'s a nice progression and a workflow that is often seen when working. The design patterns aren\'t exhaustive but give a general idea of their use. For a more complete analysis, read the Gang of Four book which [I reviewed here]({% post_url 2018/2018-11-06-gangoffour %}).\\n\\n### What should be retained from this book?\\nThe general concepts of agile programming, SOLID principles (pay more attention to these) and the diagrams.\\nThe idea of testing, refactoring and agile workflow is something you will likely encounter when working so it\'s a good idea to be familiar with it. \\nSOLID principles will follow you every day and it shows when you review code that has been written by somebody that knows these principles. They add a lot of cleanliness to your work.\\nRemember the general form of the diagrams, but don\'t focus on remembering the details of each diagram (the book doesn\'t go into to much detail anyway). \\n\\n### How does this apply to proper code?\\nThese are the basic principles which drive proper code and upon which everything else is based. This book opened my mind to working with agile principles and writing clean code, and I hope it will be the same for you."},{"id":"/2019/01/28/tools","metadata":{"permalink":"/2019/01/28/tools","source":"@site/blog/2019/01-28-tools.md","title":"Importance of Good Tools","description":"There are a lot of tools to work with code now and it\'s getting harder and harder to choose between the different editors, IDEs, compilers, linkers, build engines, version control systems and such. How do you choose between all of them? I\'ll focus mainly on editors and IDEs for the moment might come back for other tools later on. My point here is not to tell you which editor or IDE to use or not, but help you choose the correct one for you.","date":"2019-01-28T00:00:00.000Z","formattedDate":"January 28, 2019","tags":[{"label":"Practices","permalink":"/tags/practices"}],"readingTime":4.525,"hasTruncateMarker":true,"authors":[],"frontMatter":{"title":"Importance of Good Tools","tags":["Practices"]},"prevItem":{"title":"Book Review: Agile Principles, Patterns, and Practices in C#","permalink":"/2019/02/12/agile-principles-patterns-practices"},"nextItem":{"title":"Layout Update","permalink":"/2019/01/17/layout-update"}},"content":"There are a lot of tools to work with code now and it\'s getting harder and harder to choose between the different editors, IDEs, compilers, linkers, build engines, version control systems and such. How do you choose between all of them? I\'ll focus mainly on editors and IDEs for the moment might come back for other tools later on. My point here is not to tell you which editor or IDE to use or not, but help you choose the correct one for you.\\n\\n\x3c!-- truncate --\x3e\\n\\n### Solo or Team Work?\\nThere are concerns when working in a team like having a unified code style that may make you tilt in a certain direction. Most editors and IDEs nowadays come with very complete code style engines to help you format the code the way you want it with as little effort as possible. The important part is that everybody in the team works with the same code style. This helps to reduce \\"useless\\" modifications in commits (where only the spacing, indentation or line wrapping changed) which will make it easier to review code. IDEs like the JetBrains suite or Visual Studio with ReSharper offer this out of the box and you can version the code style options so that everybody uses the same settings.  Most of the IDEs will only work if you use the same one (because their settings are saved with a custom format), but some IDEs will read a .editorconfig file containing the code style settings you need.\\n\\nCheck out what your coworkers are using: chances are they\'ll help you set it up and answer your questions also.\\n\\n### What language are you working on?\\nSimpler editors handle most languages well, but don\'t handle any language exceptionally well (except the language in which it was written, or which was written for it like ELisp and VimScript). Having a more specialized IDE for your language will provide a lot of features that editors won\'t be able to provide (like running, debugging, templates, etc).\\n\\nWhat kind of work are you going to do with the language? If it\'s a simple bash script you won\'t change for a while, most editors will do the job, but if you\'re going to work on a larger project for a couple of months, a more specialized IDE will greatly help you. More complete IDEs will often provide refactoring features that will help you write better and faster code.\\n\\nThat said, it\'s always a good idea to have a preferred editor for those times you need to quickly edit a file that\'s not well supported by your IDE of choice.\\n\\n### Are you using weird key bindings?\\nThis mostly applies to those coming from the olden days of Nano, Emacs and Vim. Back then key bindings weren\'t common among different editors and so each editor created their own set of key bindings. Nowadays, IDEs will most likely come with a simple set of key bindings but if you don\'t feel like learning them, you can look into which other key bindings the IDE can support.\\n\\nI started coding using Emacs and have used it extensively for a couple of years of university. When I started working with others, I had to switch and this is a point that made me choose Rider over Visual Studio when working with C#. Visual Studio\'s support for Emacs key bindings stopped in 2010 and was added as a plugin which didn\'t work that well for the later versions, while all the JetBrains editors fully support Emacs key bindings (except C-t which has been in their backlog for a while now...). Since I still use Emacs as my main \\"quick\\" editor, it\'s nice not having to change between different key bindings for each editor I use.\\n\\n### Paying a little extra might be a good option\\nObviously when you\'re looking at fully integrated IDEs, most of them require you to pay a large amount to access a lot of the features. That cost is often easily repaid when you account for the amount of time you save doing a repeated task or writing better code. If you\'re not sure the cost is worth it, try it out first. JetBrains allows you to try out the next version of the IDE during it\'s Early Access Program, and offers Community or Student editions of a couple IDEs (just make sure you follow the constraints for these). Microsoft also has a Community edition for Visual Studio so you can try it out. Most of the time the feature differences are available on their website to better help you choose the version you need.\\n\\nOf course, if you\'re not using the extra features, you can probably check out the free alternatives they have: Eclipse, NetBeans, Android Studio, Visual Studio Code, Atom (and I\'m skipping some) or simply use your favourite editor.\\n\\n### Conclusion\\nThe IDE is the tool you\'re going to use most, so make sure you choose the best one for you needs. Try out different tools and check out new tools that come out when possible. Look for plugins that might add features to help you and make some if you feel like you\'re missing something.\\n\\nP.S.: For those wondering, I\'ve said it a little earlier, but my main tools these days are Intellij IDEA for Java and Android coding, Rider for C#, WebStorm for this blog and Emacs for pretty much all the rest."},{"id":"/2019/01/17/layout-update","metadata":{"permalink":"/2019/01/17/layout-update","source":"@site/blog/2019/01-17-layout-update.md","title":"Layout Update","description":"I recently decided to update my website and used this opportunity to learn a new (though old) technology: CSS Grid.","date":"2019-01-17T00:00:00.000Z","formattedDate":"January 17, 2019","tags":[{"label":"Update","permalink":"/tags/update"}],"readingTime":0.995,"hasTruncateMarker":true,"authors":[],"frontMatter":{"title":"Layout Update","tags":["Update"]},"prevItem":{"title":"Importance of Good Tools","permalink":"/2019/01/28/tools"},"nextItem":{"title":"Advent of Code Conclusion","permalink":"/2019/01/03/advent2018"}},"content":"I recently decided to update my website and used this opportunity to learn a new (though old) technology: CSS Grid.\\n\\n\x3c!-- truncate --\x3e\\n\\nI completely scrapped the old css (including bootstrap) and rewrote everything myself. I was surprised at how much I could do with so little SCSS since I\'ve been used to using bootstrap and other such libraries that add thousands of lines of code. My current SCSS file is under 150 lines and doesn\'t include any other css files.\\n\\nPlacing things in the page with CSS Grid is an absolute joy compared to trying to work for different screen sizes using bootstrap and I now would always suggest CSS Grid when starting a new project, especially if it\'s aimed at different screen sizes.\\n\\nI still have some work left to do, which I will continue working on in the next few weeks, adding updates like this one and maybe some lessons I learned along the way:\\n1. Filtering posts by category (with the links already present in the menu).\\n2. Adding pagination to the post list so it doesn\'t go on forever.\\n3. Adding more in-depth CSS for the posts themselves (inline code, code blocks, lists, etc)."},{"id":"/2019/01/03/advent2018","metadata":{"permalink":"/2019/01/03/advent2018","source":"@site/blog/2019/01-03-advent2018.md","title":"Advent of Code Conclusion","description":"This will be a small conclusion on my experience working of the advent of code challenge this year. I managed to finish all the problems on the 27th of December. My point was not to race for the 100 first places as other do, but simply complete the problems, which is why I was completing them the morning after they were posted, and didn\'t mind spending a little more time, especially since some of the problems were pretty complicated. I completed all the problems in 1621th place.","date":"2019-01-03T00:00:00.000Z","formattedDate":"January 3, 2019","tags":[{"label":"Challenges","permalink":"/tags/challenges"},{"label":"Advent","permalink":"/tags/advent"}],"readingTime":3.975,"hasTruncateMarker":true,"authors":[],"frontMatter":{"title":"Advent of Code Conclusion","tags":["Challenges","Advent"]},"prevItem":{"title":"Layout Update","permalink":"/2019/01/17/layout-update"},"nextItem":{"title":"Day 15: Beverage Bandits","permalink":"/2018/12/27/advent2018-15"}},"content":"This will be a small conclusion on my experience working of the advent of code challenge this year. I managed to finish all the problems on the 27th of December. My point was not to race for the 100 first places as other do, but simply complete the problems, which is why I was completing them the morning after they were posted, and didn\'t mind spending a little more time, especially since some of the problems were pretty complicated. I completed all the problems in 1621th place.\\n\\n\x3c!-- truncate --\x3e\\n\\nMy code for all the problems, including unit tests and data providers for input parsing is available [here](https://github.com/lavoiecsh/lavoiecsh.github.io/tree/master/code/advent2018).\\n\\n### Which problems gave me more trouble?\\n- 12: The second part for this problem requires calculating a large number of generations and I didn\'t initially think about looking at what is actually happening after each generation so I initially tried to make it work for the full fifty billion generations. The solution was to find a pattern to reduce the number of iterations to calculate.\\n- 15: I initially put this one aside as it seemed to take a lot of time to code (and I was right). The problem isn\'t difficult, but there are a lot of business rules in the description and it\'s easy to misread or misunderstand one or two.\\n- 18: The second part for this problem also requires calculating a large number of generations. As for problem 12, I didn\'t start looking at the actual data to find a pattern which could be used to calculate the solution a lot more efficiently.\\n- 19: The second part requires reverse engineering the code, and I initially didn\'t think about that.\\n- 23: The second part requires finding a point in a very large space that touches the most range \\"spheres\\". After a couple of attempts at calculating it, I ended up going on the subreddit for some help and took a solution from there. This is the only problem where I had to look for a solution.\\n\\n### So what did I learn from these problems? \\nIf you want to compete in the race, you need to start the moment the problem goes up and don\'t think about writing clean code (at least until you\'ve entered your answers). Most of the problems can be solved with less than 100 lines of code in most languages so it\'s still a manageable size for code you\'re going to work on only for a couple of minutes or hours. For the problems with more rules (like 15 and 24), I think it starts to become more important to write clean code so you can easily fix the rules to match the problem description.\\n\\nUnits tests were very useful to me, especially since all the problems give some simpler cases that you can use as test cases. For programmers that are used to work with test driven development, this doesn\'t really slow them down, but some of the test cases took me a lot of time to setup, mainly because I decided to split the input reading from the problem solving, which meant I had to write my test cases using a mock object and mocking the data read instead of simply reading from a different file or starting with a different string or string array. Splitting both helped to solved the problems, because I didn\'t have to think about input parsing at the same time but it did add a little more work as I had to create more tests and classes for the data providers I created.\\n\\n### What would I change next time?\\nWorking with C# and writing clean solutions was a very good exercise for the blog, but did require a lot more time to solve some of the problems. A lot of the problems require working with matrices and there are some way better languages to do that than C# (like Python or MatLab/Octave). All in all I think Python would probably be one of the best languages to solve these problems: it has a simple syntax which makes it easy to write small programs, it has powerful libraries like SciPy, NumPy, Z3 and many more which can help solve a lot of the problems, it\'s efficient enough that most solutions won\'t require minutes to compute and input reading is easy enough that you won\'t lose time with it.\\n\\nThinking outside the box earlier. If the problem requires running a lot of iterations, it\'s probably because there\'s a pattern you need to find. If the problem gives you code, you might need to reverse engineer it. If the problem makes you work with strings and characters, don\'t change it to lists of enums, it just takes too much time for nothing."},{"id":"/2018/12/27/advent2018-15","metadata":{"permalink":"/2018/12/27/advent2018-15","source":"@site/blog/2018/12-27-advent2018-15.md","title":"Day 15: Beverage Bandits","description":"Finally came back to this problem.","date":"2018-12-27T00:00:00.000Z","formattedDate":"December 27, 2018","tags":[{"label":"Challenges","permalink":"/tags/challenges"},{"label":"Advent","permalink":"/tags/advent"},{"label":"C#","permalink":"/tags/c"}],"readingTime":0.835,"hasTruncateMarker":true,"authors":[],"frontMatter":{"title":"Day 15: Beverage Bandits","tags":["Challenges","Advent","C#"]},"prevItem":{"title":"Advent of Code Conclusion","permalink":"/2019/01/03/advent2018"},"nextItem":{"title":"Day 25: Four-Dimensional Adventure","permalink":"/2018/12/27/advent2018-25"}},"content":"Finally came back to this problem.\\n\\n\x3c!-- truncate --\x3e\\n\\nAs for problem 24 with the immune system, the hardest part about this problem is making sure you read the description correctly. It took me a couple of attempts with the test cases before getting all the rules nailed down.\\n\\nI went with 3 classes in this problem:\\n- Map: containing a list of open tiles in the map and a list of units, this also contains the logic for playing a game (first part of the problem) and playing multiple games with different attack values for the elves (second part of the problem);\\n- Unit: defining the elves and goblins, this also contains the logic for how a unit plays his turn, attacks, moves, finds the nearest opponent, etc;\\n- Position: defining a position on the grid, this is usually not needed as it may be replaced by a simple tuple, but was useful as I added some fonctions to return adjacent positions and compare them directly."},{"id":"/2018/12/27/advent2018-25","metadata":{"permalink":"/2018/12/27/advent2018-25","source":"@site/blog/2018/12-27-advent2018-25.md","title":"Day 25: Four-Dimensional Adventure","description":"All the problems are now completed.","date":"2018-12-27T00:00:00.000Z","formattedDate":"December 27, 2018","tags":[{"label":"Challenges","permalink":"/tags/challenges"},{"label":"Advent","permalink":"/tags/advent"},{"label":"C#","permalink":"/tags/c"}],"readingTime":0.605,"hasTruncateMarker":true,"authors":[],"frontMatter":{"title":"Day 25: Four-Dimensional Adventure","tags":["Challenges","Advent","C#"]},"prevItem":{"title":"Day 15: Beverage Bandits","permalink":"/2018/12/27/advent2018-15"},"nextItem":{"title":"Day 23: Experimental Emergency Teleportation","permalink":"/2018/12/26/advent2018-23"}},"content":"All the problems are now completed.\\n\\n\x3c!-- truncate --\x3e\\n\\nI wasn\'t expecting there to be no second part, but welcome it nonetheless.\\n\\nFor the first part of the problem, I started by building the constellations as I receive the stars, but that always gave me numbers too high as the link between two parts of a constellations could come later in the input. So I added a phase to merge constellations that could fit together and that gave me the correct answer.\\n\\nThis is the end of the problems, so the posts will end here. I will post a conclusion in a couple of days with some things I learned, stuff I would do again, stuff I wouldn\'t do again, etc."},{"id":"/2018/12/26/advent2018-23","metadata":{"permalink":"/2018/12/26/advent2018-23","source":"@site/blog/2018/12-26-advent2018-23.md","title":"Day 23: Experimental Emergency Teleportation","description":"This is the first problem for which I had to get a solution online for the second part.","date":"2018-12-26T00:00:00.000Z","formattedDate":"December 26, 2018","tags":[{"label":"Challenges","permalink":"/tags/challenges"},{"label":"Advent","permalink":"/tags/advent"},{"label":"C#","permalink":"/tags/c"}],"readingTime":1.905,"hasTruncateMarker":true,"authors":[],"frontMatter":{"title":"Day 23: Experimental Emergency Teleportation","tags":["Challenges","Advent","C#"]},"prevItem":{"title":"Day 25: Four-Dimensional Adventure","permalink":"/2018/12/27/advent2018-25"},"nextItem":{"title":"Day 24: Immune System Simulator 20XX","permalink":"/2018/12/25/advent2018-24"}},"content":"This is the first problem for which I had to get a solution online for the second part.\\n\\n\x3c!-- truncate --\x3e\\n\\nFor the first part of the problem, I solved it by finding the nanobot with the largest radius and counting the number of nanobot in range of it.\\n\\nFor the second part, I tried a couple of different things:\\n- Brute force the search: there are 1000 nanobots in an area of 10,000,000 cubed positions, this is just not viable;\\n- Use a divide-and-conquer approach, dividing the space into 8 regions, keeping the regions with the most nanobots and continuing this way: the nanobots have a radius so big that they cover almost all the regions all the time so the number of regions to check explodes pretty quickly;\\n- Find the coordinates for each axis where the number of nanobots is the biggest and find the triple that has the highest count: here again I found around 100,000 cubed possibilities, even brute-forcing this is not viable;\\n- Using a local search approach, starting at a point and slowly moving the point towards points that have a higher count: this is prone to finding local maxima instead the of the global maxima which we want and might not return the global maximum which is the closest to the origin.\\n\\nSo after all those attempts, I decided to go check online for some help. On the [advent of code subreddit](https://www.reddit.com/r/adventofcode/), there is a post for the solutions for [this problem](https://www.reddit.com/r/adventofcode/comments/a8s17l/2018_day_23_solutions/). After reading the comments, I figured I wasn\'t the only one that needed some help with this one. A lot of the proposed solutions wouldn\'t work for all inputs, and others used a [Python library called Z3](https://github.com/Z3Prover/z3) to solve it, basically removing the grunt work of the problem. This is probably something that I should become familiar with if I want to do these problems next year also.\\n\\nI started by trying a simpler solution that was proposed by [u/EriiKKo](https://www.reddit.com/user/EriiKKo) in this [comment](https://www.reddit.com/r/adventofcode/comments/a8s17l/2018_day_23_solutions/ecdqzdg/?context=3). His solution is to create line segments from the origin to each nanobot and count the number of overlapping segments, returning the maximum count found, which is the solution. There are a couple of counter-examples, as described later in the comments, but this solution worked for my input."},{"id":"/2018/12/25/advent2018-24","metadata":{"permalink":"/2018/12/25/advent2018-24","source":"@site/blog/2018/12-25-advent2018-24.md","title":"Day 24: Immune System Simulator 20XX","description":"Another problem that had me looking at my wrong answer for a while not understanding what was happening. This time I realized that a group with negative units could attack (because it had been killed previously in the round).","date":"2018-12-25T00:00:00.000Z","formattedDate":"December 25, 2018","tags":[{"label":"Challenges","permalink":"/tags/challenges"},{"label":"Advent","permalink":"/tags/advent"},{"label":"C#","permalink":"/tags/c"}],"readingTime":0.59,"hasTruncateMarker":true,"authors":[],"frontMatter":{"title":"Day 24: Immune System Simulator 20XX","tags":["Challenges","Advent","C#"]},"prevItem":{"title":"Day 23: Experimental Emergency Teleportation","permalink":"/2018/12/26/advent2018-23"},"nextItem":{"title":"Day 22: Mode Maze","permalink":"/2018/12/22/advent2018-22"}},"content":"Another problem that had me looking at my wrong answer for a while not understanding what was happening. This time I realized that a group with negative units could attack (because it had been killed previously in the round).\\n\\n\x3c!-- truncate --\x3e\\n\\nFor the first part of the problem, I created a Group class that defined a single group and a ImmuneCombat class that defined the combat. The solution is pretty straight-forward, but requires a lot of reading and re-reading of the description to make sure you get all the rules (my mistake came from this).\\n\\nFor the second part of the problem, I simply tried every boost possible until one of them made the immune system win."},{"id":"/2018/12/22/advent2018-22","metadata":{"permalink":"/2018/12/22/advent2018-22","source":"@site/blog/2018/12-22-advent2018-22.md","title":"Day 22: Mode Maze","description":"The first part for this problem was pretty straight forward, simply calculate the erosion level for each region and transform that into region types before summing the ones in the desired region. Since you\'re multiplying big integers, at some point there be overflow, but since you\'re also doing modulo operations, you can work with modulo arithmetic from the start and only conserve the remainder when computing the erosion level of a region.","date":"2018-12-22T00:00:00.000Z","formattedDate":"December 22, 2018","tags":[{"label":"Challenges","permalink":"/tags/challenges"},{"label":"Advent","permalink":"/tags/advent"},{"label":"C#","permalink":"/tags/c"}],"readingTime":0.83,"hasTruncateMarker":true,"authors":[],"frontMatter":{"title":"Day 22: Mode Maze","tags":["Challenges","Advent","C#"]},"prevItem":{"title":"Day 24: Immune System Simulator 20XX","permalink":"/2018/12/25/advent2018-24"},"nextItem":{"title":"Day 21: Chronal Conversion","permalink":"/2018/12/21/advent2018-21"}},"content":"The first part for this problem was pretty straight forward, simply calculate the erosion level for each region and transform that into region types before summing the ones in the desired region. Since you\'re multiplying big integers, at some point there be overflow, but since you\'re also doing modulo operations, you can work with modulo arithmetic from the start and only conserve the remainder when computing the erosion level of a region.\\n\\n\x3c!-- truncate --\x3e\\n\\nThe second part was a little more complicated and took me quite some time more. I ended up with a distance matrix calculation where I would take the values around it depending on the tool and the region types. My original attempt got me numbers too low because I was switching tools regardless of the type of the previous region. My second attempt was too high because I didn\'t extend my matrix enough. I ended up having to multiply the size of my map by 3 to get the correct solution."},{"id":"/2018/12/21/advent2018-21","metadata":{"permalink":"/2018/12/21/advent2018-21","source":"@site/blog/2018/12-21-advent2018-21.md","title":"Day 21: Chronal Conversion","description":"Back to assembler for this one.","date":"2018-12-21T00:00:00.000Z","formattedDate":"December 21, 2018","tags":[{"label":"Challenges","permalink":"/tags/challenges"},{"label":"Advent","permalink":"/tags/advent"},{"label":"C#","permalink":"/tags/c"}],"readingTime":0.935,"hasTruncateMarker":true,"authors":[],"frontMatter":{"title":"Day 21: Chronal Conversion","tags":["Challenges","Advent","C#"]},"prevItem":{"title":"Day 22: Mode Maze","permalink":"/2018/12/22/advent2018-22"},"nextItem":{"title":"Day 20: A Regular Map","permalink":"/2018/12/20/advent2018-20"}},"content":"Back to assembler for this one.\\n\\n\x3c!-- truncate --\x3e\\n\\nTo solve this one, I immediately started reverse engineering the code as I was guessing running the code with different values for register 0 would just require way too much time, especially since it\'s possible for the program to never end. I noticed in my program that the only time register 0 is used, is to compare it with register 5 on instruction 28: if they are both equal the program stops, otherwise it loops back.\\n\\nI then made my program run until I hit instruction 28 and return the value of register 5 at that point. This solved the first part of the problem.\\n\\nFor the second part, I reverse engineering further but failed as I had forgotten a branch I think. So I decided to record all the values in register 5 at instruction 28 until I found a value I had already seen. This gives all the values for register 0 for which the program eventually halts. The last of these is then the value for which the program takes the most time to stop."},{"id":"/2018/12/20/advent2018-20","metadata":{"permalink":"/2018/12/20/advent2018-20","source":"@site/blog/2018/12-20-advent2018-20.md","title":"Day 20: A Regular Map","description":"It\'s back to easier problems with this one.","date":"2018-12-20T00:00:00.000Z","formattedDate":"December 20, 2018","tags":[{"label":"Challenges","permalink":"/tags/challenges"},{"label":"Advent","permalink":"/tags/advent"},{"label":"C#","permalink":"/tags/c"}],"readingTime":1.78,"hasTruncateMarker":true,"authors":[],"frontMatter":{"title":"Day 20: A Regular Map","tags":["Challenges","Advent","C#"]},"prevItem":{"title":"Day 21: Chronal Conversion","permalink":"/2018/12/21/advent2018-21"},"nextItem":{"title":"Day 19: Go With The Flow","permalink":"/2018/12/19/advent2018-19"}},"content":"It\'s back to easier problems with this one.\\n\\n\x3c!-- truncate --\x3e\\n\\nMy solution was to create a dictionary of rooms and their doors. This is easily done in C# with a flags enum:\\n\\n```C#\\n[Flags]\\nprivate enum RoomDoors\\n{\\n    None = 0,\\n    North = 1,\\n    South = 2,\\n    East = 4,\\n    West = 8\\n}\\n```\\n\\nThis allows to create rooms with multiple doors by combining them as such: ```RoomDoors.North | RoomDoors.South | RoomDoors.East``` (this room would have a door on the north side, south side and east side, but no door on the west side). The only \\"constraint\\" of flags enum in C# is that your values should be powers of two: think of it as being bits lighting up in a byte. This also allows boolean arithmetic like adding a door to a room: ```doors |= RoomDoors.North``` and easy checking of doors in a room using ```doors.HasFlag(RoomDoors.North)```.\\n\\nI created a RegexParser class to parse the input using a stack of the current positions. The basic directions pop the stack, add a door depending on the direction and push the new position on the stack. The opening parentheses copy the top position of the stack, the closing parentheses remove the top position and the vertical bar removes the top and copies the second (now top), effectively going back to the previous position and copying it.\\n\\nThis class was used to drive a MapBuilder class that contained the doors for each room in a dictionary and a method to add a new door beside a door considering the direction.\\n\\nOnce the map was created, I created a DistanceCalculator class that takes the dictionary of rooms with their doors and created dictionary of rooms with their distance from the starting position. To calculate the distance I looped through each room and checked the smallest distance between it\'s four possible adjacent rooms, increasing it by 1 and saving it to the new room.\\n\\nWith this distance map, the first part of the problem is solved by finding the largest distance in the map and the second part is solved by counting the number of distances more than 1000."},{"id":"/2018/12/19/advent2018-19","metadata":{"permalink":"/2018/12/19/advent2018-19","source":"@site/blog/2018/12-19-advent2018-19.md","title":"Day 19: Go With The Flow","description":"I\'m starting to doubt my abilities as a programmer as more and more of the problems\' second parts are winning over me.","date":"2018-12-19T00:00:00.000Z","formattedDate":"December 19, 2018","tags":[{"label":"Challenges","permalink":"/tags/challenges"},{"label":"Advent","permalink":"/tags/advent"},{"label":"C#","permalink":"/tags/c"}],"readingTime":1.6,"hasTruncateMarker":true,"authors":[],"frontMatter":{"title":"Day 19: Go With The Flow","tags":["Challenges","Advent","C#"]},"prevItem":{"title":"Day 20: A Regular Map","permalink":"/2018/12/20/advent2018-20"},"nextItem":{"title":"Day 18: Settlers of The North Pole","permalink":"/2018/12/18/advent2018-18"}},"content":"I\'m starting to doubt my abilities as a programmer as more and more of the problems\' second parts are winning over me.\\n\\n\x3c!-- truncate --\x3e\\n\\nI reused most of the code I did in problem number 16 for this problem. It helped a lot for the first part of the problem. The only difference is that I set the instruction pointer to the correct register before starting the execution of the program.\\n\\nThis worked well for the first part of the problem, but the simple change of starting with ```[1, 0, 0, 0, 0, 0]``` instead of ```[0, 0, 0, 0, 0, 0]``` for the second part made my program take a lot longer to execute. After a couple of vain attempts at optimization, I decided to go look on the advent subreddit, I found out most people reverse engineered their code into a simpler format.\\n\\nAfter watching the register during the execution and the code for my program, I started out with this code:\\n```C#\\nlong r0 = 0;\\nlong r1 = 10551383;\\nlong r2 = 1;\\nlong r4;\\n\\ndo\\n{\\n    r4 = 1;\\n    do\\n    {\\n        if ((r2 * r4) == r1) r0 += r2;\\n        r4++;\\n    }\\n    while (r4 <= r1);\\n    r2++;\\n}\\nwhile (r2 <= r1);\\nreturn r0.ToString();\\n```\\n\\nBut even this took a while to compute, so I analyzed the inner loop a bit more and found out it\'s just checking if there is a factor of ```r1/r2``` and adds it to ```r0```. I simplified the code to this and found my solution with it:\\n\\n```C#\\n long r0 = 0;\\n const int r1 = 10551383;\\n long r2 = 1;\\n\\ndo\\n{\\n    var r4 = (decimal) r1 / r2;\\n    if (r4 == Math.Floor(r4)) r0 += r2;\\n    r2++;\\n}\\nwhile (r2 <= r1);\\nreturn r0.ToString();\\n```\\n\\nFinding the solution helped me regain a little confidence that I can solve the other problems I skipped previously with some similar work."},{"id":"/2018/12/18/advent2018-18","metadata":{"permalink":"/2018/12/18/advent2018-18","source":"@site/blog/2018/12-18-advent2018-18.md","title":"Day 18: Settlers of The North Pole","description":"Second problem I have trouble with the second part.","date":"2018-12-18T00:00:00.000Z","formattedDate":"December 18, 2018","tags":[{"label":"Challenges","permalink":"/tags/challenges"},{"label":"Advent","permalink":"/tags/advent"},{"label":"C#","permalink":"/tags/c"}],"readingTime":0.66,"hasTruncateMarker":true,"authors":[],"frontMatter":{"title":"Day 18: Settlers of The North Pole","tags":["Challenges","Advent","C#"]},"prevItem":{"title":"Day 19: Go With The Flow","permalink":"/2018/12/19/advent2018-19"},"nextItem":{"title":"Day 16: Chronal Classification","permalink":"/2018/12/17/advent2018-16"}},"content":"Second problem I have trouble with the second part.\\n\\n\x3c!-- truncate --\x3e\\n\\nFor the first part, I solved it by creating a map of the area and going through each square to compute it\'s next value.\\n\\nThis simple approach works well for the first part of the problem, but does not scale well to a larger number of iterations like the second part of the problem requires. I will have to come back to this one also when I have a little more time.\\n\\nUPDATE: I have solved the second part for this on December 20th by keeping a list of all the maps calculated so far and checking when a loop occurs. This reduces the computation time to around half a second as there is only about 550 iterations to do."},{"id":"/2018/12/17/advent2018-16","metadata":{"permalink":"/2018/12/17/advent2018-16","source":"@site/blog/2018/12-17-advent2018-16.md","title":"Day 16: Chronal Classification","description":"I was pretty busy this weekend so I didn\'t have time to do the problems. I started on problem 15 but realized it would take me a lot of time, so I decided to go ahead and complete problems 16 and 17 and come back to 15 later.","date":"2018-12-17T00:00:00.000Z","formattedDate":"December 17, 2018","tags":[{"label":"Challenges","permalink":"/tags/challenges"},{"label":"Advent","permalink":"/tags/advent"},{"label":"C#","permalink":"/tags/c"}],"readingTime":0.715,"hasTruncateMarker":true,"authors":[],"frontMatter":{"title":"Day 16: Chronal Classification","tags":["Challenges","Advent","C#"]},"prevItem":{"title":"Day 18: Settlers of The North Pole","permalink":"/2018/12/18/advent2018-18"},"nextItem":{"title":"Day 17: Reservoir Research","permalink":"/2018/12/17/advent2018-17"}},"content":"I was pretty busy this weekend so I didn\'t have time to do the problems. I started on problem 15 but realized it would take me a lot of time, so I decided to go ahead and complete problems 16 and 17 and come back to 15 later.\\n\\n\x3c!-- truncate --\x3e\\n\\nFor problem 16, I created a simple Processor class that contains registers and can execute an operation. To solve the first part, I looped through each operation and counted the number of times the registers matched for each test. The input is small enough that it\'s not a problem.\\n\\nFor the second part of the problem, I looped through each test, fixing the mapping between the opcode and the operation until all opcodes were found. After that, I executed each operation on the processor and returned the value of the first register."},{"id":"/2018/12/17/advent2018-17","metadata":{"permalink":"/2018/12/17/advent2018-17","source":"@site/blog/2018/12-17-advent2018-17.md","title":"Day 17: Reservoir Research","description":"This one took me a while because I was a little off on my first answers. I forgot to remove the first empty lines of the clay map, so I was 9 water tiles over the correct answer.","date":"2018-12-17T00:00:00.000Z","formattedDate":"December 17, 2018","tags":[{"label":"Challenges","permalink":"/tags/challenges"},{"label":"Advent","permalink":"/tags/advent"},{"label":"C#","permalink":"/tags/c"}],"readingTime":0.6,"hasTruncateMarker":true,"authors":[],"frontMatter":{"title":"Day 17: Reservoir Research","tags":["Challenges","Advent","C#"]},"prevItem":{"title":"Day 16: Chronal Classification","permalink":"/2018/12/17/advent2018-16"},"nextItem":{"title":"Day 14: Chocolate Charts","permalink":"/2018/12/14/advent2018-14"}},"content":"This one took me a while because I was a little off on my first answers. I forgot to remove the first empty lines of the clay map, so I was 9 water tiles over the correct answer.\\n\\n\x3c!-- truncate --\x3e\\n\\nApart from that, the first part of the problem took me a while to come up with a decent solution. I ended up creating a small algorithm to calculate flows which fills a reservoir and reinserts new flows into a queue for the main algorithm to go through.\\n\\nThe second part of the problem was probably one of the easiest modifications I had to do to get the answer. I counted only 1 type of tile instead of 2."},{"id":"/2018/12/14/advent2018-14","metadata":{"permalink":"/2018/12/14/advent2018-14","source":"@site/blog/2018/12-14-advent2018-14.md","title":"Day 14: Chocolate Charts","description":"This problem was similar to the Marble Game on day 9, so I started with a solution similar to the one I used for that problem, using a linked list and having the two elves as linked list nodes that can move along the list. It worked fine for the first part of the problem, but started running pretty slow for the second part of the problem.","date":"2018-12-14T00:00:00.000Z","formattedDate":"December 14, 2018","tags":[{"label":"Challenges","permalink":"/tags/challenges"},{"label":"Advent","permalink":"/tags/advent"},{"label":"C#","permalink":"/tags/c"}],"readingTime":0.835,"hasTruncateMarker":true,"authors":[],"frontMatter":{"title":"Day 14: Chocolate Charts","tags":["Challenges","Advent","C#"]},"prevItem":{"title":"Day 17: Reservoir Research","permalink":"/2018/12/17/advent2018-17"},"nextItem":{"title":"Day 13: Mine Cart Madness","permalink":"/2018/12/13/advent2018-13"}},"content":"This problem was similar to the Marble Game on day 9, so I started with a solution similar to the one I used for that problem, using a linked list and having the two elves as linked list nodes that can move along the list. It worked fine for the first part of the problem, but started running pretty slow for the second part of the problem.\\n\\n\x3c!-- truncate --\x3e\\n\\nFor the second part of the problem, I ended up reverting to a simple string building technique and keeping the two elves as indexes on that string. This works because each recipe has a score of only a single character. Even with this string solution, I had to add another string containing only the last couple of recipe scores inserted to reduce the checking time against the given input. Even with this, my code takes about 7 minutes to find the solution. I might come back to this one to try and optimize it a bit more."},{"id":"/2018/12/13/advent2018-13","metadata":{"permalink":"/2018/12/13/advent2018-13","source":"@site/blog/2018/12-13-advent2018-13.md","title":"Day 13: Mine Cart Madness","description":"Nice little problem with a more complicated description but a somewhat simple solution.","date":"2018-12-13T00:00:00.000Z","formattedDate":"December 13, 2018","tags":[{"label":"Challenges","permalink":"/tags/challenges"},{"label":"Advent","permalink":"/tags/advent"},{"label":"C#","permalink":"/tags/c"}],"readingTime":0.57,"hasTruncateMarker":true,"authors":[],"frontMatter":{"title":"Day 13: Mine Cart Madness","tags":["Challenges","Advent","C#"]},"prevItem":{"title":"Day 14: Chocolate Charts","permalink":"/2018/12/14/advent2018-14"},"nextItem":{"title":"Day 12: Subterranean Sustainability","permalink":"/2018/12/12/advent2018-12"}},"content":"Nice little problem with a more complicated description but a somewhat simple solution.\\n\\n\x3c!-- truncate --\x3e\\n\\nI started by creating classes for the map and the carts and made it so I was able to read the given input. I then added unit tests to make the carts move and finally solved the first part by making the carts move until a collision was found.\\n\\nFor the second part, I reused everything I already had and just removed the carts that collided each time there was a collision detected.\\n\\nSolving this quickly helped me gain a little more confidence that I\'ll be able to do the rest of the problems, especially after yesterday\'s problem."},{"id":"/2018/12/12/advent2018-12","metadata":{"permalink":"/2018/12/12/advent2018-12","source":"@site/blog/2018/12-12-advent2018-12.md","title":"Day 12: Subterranean Sustainability","description":"This is the first problem that I still haven\'t an efficient way to solve the second part.","date":"2018-12-12T00:00:00.000Z","formattedDate":"December 12, 2018","tags":[{"label":"Challenges","permalink":"/tags/challenges"},{"label":"Advent","permalink":"/tags/advent"},{"label":"C#","permalink":"/tags/c"}],"readingTime":1.195,"hasTruncateMarker":true,"authors":[],"frontMatter":{"title":"Day 12: Subterranean Sustainability","tags":["Challenges","Advent","C#"]},"prevItem":{"title":"Day 13: Mine Cart Madness","permalink":"/2018/12/13/advent2018-13"},"nextItem":{"title":"Day 11: Chronal Charge","permalink":"/2018/12/11/advent2018-11"}},"content":"This is the first problem that I still haven\'t an efficient way to solve the second part.\\n\\n\x3c!-- truncate --\x3e\\n\\nI went with a pretty simple solution for the first part, calculating the next generation by looking up whether each plant is alive or not in the notes. This worked fine for 20 generations.\\n\\nScaling this to the second part and it\'s 50,000,000,000 generations just isn\'t cutting it. After some tests, my code runs 1,000,000 generations in about 7 seconds. 50 billion generations would take me around 97 hours of computing which is doable but not something I want to run.\\n\\nI skipped the second part for today and will come back to it later when I have more time or when I have an idea to improve my solution. My remaining ideas are to try to parallelize the computing of a generation or use memoization and check if some sections of the plants have been calculated before.\\n\\nUPDATE: I came back to this problem on December 20th and noticed that at some point the cavern is full and just moves towards the right. So I changed my code to accommodate for this by checking if my state didn\'t change from the last iteration and checking the difference in the sum from the last iteration. At this point I saved the number of iterations remaining and simply multiplied that by the difference and added the last sum I saw."},{"id":"/2018/12/11/advent2018-11","metadata":{"permalink":"/2018/12/11/advent2018-11","source":"@site/blog/2018/12-11-advent2018-11.md","title":"Day 11: Chronal Charge","description":"Another harder problem. The first part was pretty simple and didn\'t take me too much time to solve, but adapting for the second part of the problem took a lot more time.","date":"2018-12-11T00:00:00.000Z","formattedDate":"December 11, 2018","tags":[{"label":"Challenges","permalink":"/tags/challenges"},{"label":"Advent","permalink":"/tags/advent"},{"label":"C#","permalink":"/tags/c"}],"readingTime":2.195,"hasTruncateMarker":true,"authors":[],"frontMatter":{"title":"Day 11: Chronal Charge","tags":["Challenges","Advent","C#"]},"prevItem":{"title":"Day 12: Subterranean Sustainability","permalink":"/2018/12/12/advent2018-12"},"nextItem":{"title":"Day 10: The Stars Align","permalink":"/2018/12/10/advent2018-10"}},"content":"Another harder problem. The first part was pretty simple and didn\'t take me too much time to solve, but adapting for the second part of the problem took a lot more time.\\n\\n\x3c!-- truncate --\x3e\\n\\nI originally solved the first part by using a simple matrix of integers and calculating all the possible 3x3 squares in there. This was done with a procedural style (no objects, just functions).\\n\\nWhen I got to the second part of the problem, I tried adapting that procedural solution to the new problem, but it required way too much time to find the solution. So I switched to an object-oriented approach with the following classes:\\n- **Cell**: containing the power level for a cell and the method to compute it. I realized afterwards that this was not necessary and transformed into a static class with a single computation method.\\n- **CellGrid**: containing the position of the top left cell in the grid, the size of the grid and it\'s power level. It also contains a method to create a new CellGrid at the same position which has a size of one more than the current CellGrid, this was added to reduce computation time by using the existing computed cell grids to compute the next size of cell grids. There are also methods to easily compare these by power level.\\n- **PowerGrid**: containing the complete power grid which the cell grids use to compute their sum. It also has a method to find the most powerful CellGrid of a given size (which is used to solve the first part of the problem).\\n- **SplitPowerGrid**: containing all the cell grids computed for a given size. This class also contains a method to compute the next level of cell grids and a method to find the most powerful CellGrid for any size by incrementally increasing it\'s size and finding the most powerful CellGrid for the current size until all sizes are checked. This gives the solution to the second part of the problem.\\n\\nEven with the optimization of calculating the next size of cell grids with current size, the solution takes around 30 seconds to be computed. I\'m starting to give myself a 1-minute maximum computing time, so this still fits, but I\'m guessing the next problems might become harder to fit into that time frame.\\n\\nEven though I solved this using C#, and I think I will continue using C# for the remainder of the problems so that all the solutions are together, this problem would have been a lot easier to solve using a language that has better support for matrices like MatLab/Octave or Python."},{"id":"/2018/12/10/advent2018-10","metadata":{"permalink":"/2018/12/10/advent2018-10","source":"@site/blog/2018/12-10-advent2018-10.md","title":"Day 10: The Stars Align","description":"So this one really took me by surprise at the start and had me trying a lot of different stuff to find the best solution.","date":"2018-12-10T00:00:00.000Z","formattedDate":"December 10, 2018","tags":[{"label":"Challenges","permalink":"/tags/challenges"},{"label":"Advent","permalink":"/tags/advent"},{"label":"C#","permalink":"/tags/c"}],"readingTime":0.795,"hasTruncateMarker":true,"authors":[],"frontMatter":{"title":"Day 10: The Stars Align","tags":["Challenges","Advent","C#"]},"prevItem":{"title":"Day 11: Chronal Charge","permalink":"/2018/12/11/advent2018-11"},"nextItem":{"title":"Day 9: Marble Mania","permalink":"/2018/12/09/advent2018-09"}},"content":"So this one really took me by surprise at the start and had me trying a lot of different stuff to find the best solution.\\n\\n\x3c!-- truncate --\x3e\\n\\nI ended up coding a little program to print the contents of the sky to a file and looking it up. At some point I realized the output would probably be the smallest output possible and so I made my solution iterate the moving of the lights until the size of the sky was as small as possible.\\n\\nFor the first part of the problem, I just printed out the smallest sky found while iterating and moving the lights. Coding something to recognize the letters would have been a lot more complicated considering I had no idea the shape they used to print them.\\n\\nFor the second part of the problem, I used the same method as for the first part and then returned the amount of iterations that were completed."},{"id":"/2018/12/09/advent2018-09","metadata":{"permalink":"/2018/12/09/advent2018-09","source":"@site/blog/2018/12-09-advent2018-09.md","title":"Day 9: Marble Mania","description":"Today\'s problem came with a pretty complex explanation, but solving the first part was pretty simple. I created a MarbleGame class that dealt with the actual game mechanics. My solution was pretty straight forward by using a list to save the circle\'s state and loop through each marble. It worked pretty good for finding the solution for the first part of the problem.","date":"2018-12-09T00:00:00.000Z","formattedDate":"December 9, 2018","tags":[{"label":"Challenges","permalink":"/tags/challenges"},{"label":"Advent","permalink":"/tags/advent"},{"label":"C#","permalink":"/tags/c"}],"readingTime":1.095,"hasTruncateMarker":true,"authors":[],"frontMatter":{"title":"Day 9: Marble Mania","tags":["Challenges","Advent","C#"]},"prevItem":{"title":"Day 10: The Stars Align","permalink":"/2018/12/10/advent2018-10"},"nextItem":{"title":"Day 8: Memory Maneuver","permalink":"/2018/12/08/advent2018-08"}},"content":"Today\'s problem came with a pretty complex explanation, but solving the first part was pretty simple. I created a MarbleGame class that dealt with the actual game mechanics. My solution was pretty straight forward by using a list to save the circle\'s state and loop through each marble. It worked pretty good for finding the solution for the first part of the problem.\\n\\n\x3c!-- truncate --\x3e\\n\\nI then hit a wall when reusing this solution for the second part of the problem, as the numbers become a lot bigger. My first attempt took over 45 minutes and ended up overflowing. I then tried to switch to 64 bit integers and initializing my list with enough memory so it wouldn\'t need to expand during the calculations, but that also took more than 45 minutes. At least it gave me the correct answer.\\n\\nThis is where I start expecting harder problems to start coming and make me think of optimizations and/or better solutions.\\n\\n### Update\\nAlthough my solution was working with a C# List, I didn\'t like the time it took to find the solution, so I went back and rewrote a part of it. I changed the list to use a doubly linked list (LinkedList in C#). That reduced the computation time from 45 minutes to less than 2 seconds."},{"id":"/2018/12/08/advent2018-08","metadata":{"permalink":"/2018/12/08/advent2018-08","source":"@site/blog/2018/12-08-advent2018-08.md","title":"Day 8: Memory Maneuver","description":"First problem where I used recursion. Traversing trees is just so much easier with recursion.","date":"2018-12-08T00:00:00.000Z","formattedDate":"December 8, 2018","tags":[{"label":"Challenges","permalink":"/tags/challenges"},{"label":"Advent","permalink":"/tags/advent"},{"label":"C#","permalink":"/tags/c"}],"readingTime":0.755,"hasTruncateMarker":true,"authors":[],"frontMatter":{"title":"Day 8: Memory Maneuver","tags":["Challenges","Advent","C#"]},"prevItem":{"title":"Day 9: Marble Mania","permalink":"/2018/12/09/advent2018-09"},"nextItem":{"title":"Day 7: The Sum of Its Parts","permalink":"/2018/12/07/advent2018-07"}},"content":"First problem where I used recursion. Traversing trees is just so much easier with recursion.\\n\\n\x3c!-- truncate --\x3e\\n\\nI created the tree by creating a recursive algorithm to create nodes and return the head node. With that, the first part of the problem is solved by summing the metadata for each node and adding to it the sum of the metadata of it\'s children recursively. This is easily done using LINQ\'s aggregate function (similar to reduce in LISP):\\n\\n```C#\\npublic int MetadataSum()\\n{\\n    return children.Aggregate(metadata.Sum(), (acc, cur) => acc + cur.MetadataSum());\\n}\\n```\\nAs for the second part of the problem, calculating the value is just a more complicated sum, which can also be solved using an aggregation:\\n\\n```C#\\npublic int Value()\\n{\\n    return children.Any() ? metadata.Aggregate(0, (acc, md) => acc + ChildValue(md)) : metadata.Sum();\\n}\\n\\nprivate int ChildValue(int childIndex)\\n{\\n    return childIndex > children.Count ? 0 : children[childIndex-1].Value();\\n}\\n```"},{"id":"/2018/12/07/advent2018-07","metadata":{"permalink":"/2018/12/07/advent2018-07","source":"@site/blog/2018/12-07-advent2018-07.md","title":"Day 7: The Sum of Its Parts","description":"Nice little graph problem today. I started by creating a Step class which contained references to other steps it depended on. The first part was then solved by looping and flagging steps as completed until all step where completed. Finding the next step to complete simply involved a little LINQ to determine the first (considering a list of steps ordered alphabetically) incomplete step for which all its requirements are completed:","date":"2018-12-07T00:00:00.000Z","formattedDate":"December 7, 2018","tags":[{"label":"Challenges","permalink":"/tags/challenges"},{"label":"Advent","permalink":"/tags/advent"},{"label":"C#","permalink":"/tags/c"}],"readingTime":1.375,"hasTruncateMarker":true,"authors":[],"frontMatter":{"title":"Day 7: The Sum of Its Parts","tags":["Challenges","Advent","C#"]},"prevItem":{"title":"Day 8: Memory Maneuver","permalink":"/2018/12/08/advent2018-08"},"nextItem":{"title":"Day 6: Chronal Coordinates","permalink":"/2018/12/06/advent2018-06"}},"content":"Nice little graph problem today. I started by creating a Step class which contained references to other steps it depended on. The first part was then solved by looping and flagging steps as completed until all step where completed. Finding the next step to complete simply involved a little LINQ to determine the first (considering a list of steps ordered alphabetically) incomplete step for which all its requirements are completed:\\n\\n\x3c!-- truncate --\x3e\\n\\n```C#\\nvar nextStep = steps.First(s => !s.IsCompleted && s.Requirements.All(r => r.IsCompleted));\\n```\\n\\nFor the second part, I thought of multiple possible solutions but ended up doing a simple matrix-like solution similar to the problem description example. This is done by assigning available steps to each idle worker, increasing the time by 1 second and starting over until all steps are completed.\\n\\nAnother possible solution could be to use a priority queue to determine the next completed step, reduce the time for the other running tasks according to the time spent to complete it and start the next task in the queue as long as there are enough workers. This solution could be implemented without creating a Worker class as I did.\\n\\nAnother possible approach could involve have workers push events when their step is completed and have an event handler that would assign him the next available step. This approach is similar to what is done in task scheduling programs, as those used on computing servers for example. As the steps are fictional here, it would involve creating a fictional task to complete (like simply waiting or watching a counter), so it would require a lot more work than the simpler solutions."},{"id":"/2018/12/06/advent2018-06","metadata":{"permalink":"/2018/12/06/advent2018-06","source":"@site/blog/2018/12-06-advent2018-06.md","title":"Day 6: Chronal Coordinates","description":"This problem had me thinking a little more at the start, especially in how should I determine if a location\'s area is finite or not. I ended up calculating the areas of each location by going through each possible coordinate in the map and finding the closest location to it, then if a location\'s area contained a coordinate on the border of the map, that location\'s area should be infinite.","date":"2018-12-06T00:00:00.000Z","formattedDate":"December 6, 2018","tags":[{"label":"Challenges","permalink":"/tags/challenges"},{"label":"Advent","permalink":"/tags/advent"},{"label":"C#","permalink":"/tags/c"}],"readingTime":0.76,"hasTruncateMarker":true,"authors":[],"frontMatter":{"title":"Day 6: Chronal Coordinates","tags":["Challenges","Advent","C#"]},"prevItem":{"title":"Day 7: The Sum of Its Parts","permalink":"/2018/12/07/advent2018-07"},"nextItem":{"title":"Day 5: Alchemical Reduction","permalink":"/2018/12/05/advent2018-05"}},"content":"This problem had me thinking a little more at the start, especially in how should I determine if a location\'s area is finite or not. I ended up calculating the areas of each location by going through each possible coordinate in the map and finding the closest location to it, then if a location\'s area contained a coordinate on the border of the map, that location\'s area should be infinite.\\n\\n\x3c!-- truncate --\x3e\\n\\nSo for the first part of the problem, with the area of each location, I removed those with infinite areas and returned the largest area among the remaining locations.\\n\\nAs for the second part of the problem, you don\'t need to calculate the area, you only need to loop through all the coordinates, calculate the sum of the distance to each location and count the number of coordinates for which this sum is smaller than the given maximum sum."},{"id":"/2018/12/05/advent2018-05","metadata":{"permalink":"/2018/12/05/advent2018-05","source":"@site/blog/2018/12-05-advent2018-05.md","title":"Day 5: Alchemical Reduction","description":"Back to string manipulations for this one. Nice problem but I found the solution a little to simple compared to the last two problems, especially for the second part.","date":"2018-12-05T00:00:00.000Z","formattedDate":"December 5, 2018","tags":[{"label":"Challenges","permalink":"/tags/challenges"},{"label":"Advent","permalink":"/tags/advent"},{"label":"C#","permalink":"/tags/c"}],"readingTime":0.6,"hasTruncateMarker":true,"authors":[],"frontMatter":{"title":"Day 5: Alchemical Reduction","tags":["Challenges","Advent","C#"]},"prevItem":{"title":"Day 6: Chronal Coordinates","permalink":"/2018/12/06/advent2018-06"},"nextItem":{"title":"Day 4: Repose Record","permalink":"/2018/12/04/advent2018-04"}},"content":"Back to string manipulations for this one. Nice problem but I found the solution a little to simple compared to the last two problems, especially for the second part.\\n\\n\x3c!-- truncate --\x3e\\n\\nI solved the first part using a for loop inside a do-while loop to react all elements in the polymer until it couldn\'t be reacted further. Using ASCII codes helps a lot in checking whether adjacent units are of the same type and polarized or not: ```Math.Abs(firstUnit - secondUnit) == 32```.\\n\\nThe solution to the second part is basically given in the problem description: removing each possible unit, calculating the reactions and finding the smallest reacted polymer. It\'s basically just 26 times the first part of the problem."},{"id":"/2018/12/04/advent2018-04","metadata":{"permalink":"/2018/12/04/advent2018-04","source":"@site/blog/2018/12-04-advent2018-04.md","title":"Day 4: Repose Record","description":"Another fun problem today.","date":"2018-12-04T00:00:00.000Z","formattedDate":"December 4, 2018","tags":[{"label":"Challenges","permalink":"/tags/challenges"},{"label":"Advent","permalink":"/tags/advent"},{"label":"C#","permalink":"/tags/c"}],"readingTime":1.255,"hasTruncateMarker":true,"authors":[],"frontMatter":{"title":"Day 4: Repose Record","tags":["Challenges","Advent","C#"]},"prevItem":{"title":"Day 5: Alchemical Reduction","permalink":"/2018/12/05/advent2018-05"},"nextItem":{"title":"Day 3: No Matter How You Slice It","permalink":"/2018/12/03/advent2018-03"}},"content":"Another fun problem today.\\n\\n\x3c!-- truncate --\x3e\\n\\nI started the day with some refactoring of my code from the last three days ensuring everything still ran correctly with my unit tests, moving the creation of elements to a DataProvider interface which is implemented by different classes depending on the type wanted (int, string, claim, and now guard). This also moved the regular expression part of the input handling to the data providers instead of the problem solvers, making the unit tests for the solvers easier and the unit tests for the data providers more complete.\\n\\nMy guard class contains the id of the guard and a list of all the intervals where the guard slept. It was pretty easy to build the data by first sorting the lines in the file, as the timestamp was in a easily sortable format.\\n\\nThe solution to the first part of the problem is to find the guard with the most minutes asleep (by summing all the intervals for each guard), and then find the minute where he was most asleep.\\n\\nThe solution to the second part of the problem is just a invert in the steps for the solution to the first part. Find the minute at which each guard slept the most and then find the guard that slept the most out of those minutes.\\n\\nThe code is available in my github repository: [advent solutions code](https://github.com/lavoiecsh/lavoiecsh.github.io/tree/master/code/advent2018) and to those interested, check the commit for today as it is a nice exercise in refactoring."},{"id":"/2018/12/03/advent2018-03","metadata":{"permalink":"/2018/12/03/advent2018-03","source":"@site/blog/2018/12-03-advent2018-03.md","title":"Day 3: No Matter How You Slice It","description":"First problem with a more complicated input and problem. I solved these by making a class defining a claim (containing the id, position, size) and another class defining the canvas (containing a matrix of claims touching each square inch). The claims are created by parsing each line with a regular expression.","date":"2018-12-03T00:00:00.000Z","formattedDate":"December 3, 2018","tags":[{"label":"Challenges","permalink":"/tags/challenges"},{"label":"Advent","permalink":"/tags/advent"},{"label":"C#","permalink":"/tags/c"}],"readingTime":1.53,"hasTruncateMarker":true,"authors":[],"frontMatter":{"title":"Day 3: No Matter How You Slice It","tags":["Challenges","Advent","C#"]},"prevItem":{"title":"Day 4: Repose Record","permalink":"/2018/12/04/advent2018-04"},"nextItem":{"title":"Day 2: Inventory Management System","permalink":"/2018/12/02/advent2018-02"}},"content":"First problem with a more complicated input and problem. I solved these by making a class defining a claim (containing the id, position, size) and another class defining the canvas (containing a matrix of claims touching each square inch). The claims are created by parsing each line with a regular expression.\\n\\n\x3c!-- truncate --\x3e\\n\\nMy first big dilemma was between using a mathematical approach to find the regions of conflict between each pair of claim and using a matrix and just record everything in a matrix. I checked the input for the problem and noticed there was over 1200 claims with areas under 100x100 inches. Calculating the regions for all the pairs requires ```O(n\xb2)``` calculations which would amount to around 1.5M calculations, while using a matrix would require ```O(nm\xb2)``` updates to the matrix which would be at most 12M. Evaluating the individual calculations at a larger cost than an update, I opted for the matrix solution as it seemed easier to solve the first part of the solution.\\n\\nUpon reading the first part of the problem, I started with a simple matrix of integers counting the number of claims on each square. The solution was then to count the number of squares where there was only one claim.\\n\\nWhen I arrived at the second part of the problem, I noticed my solutions wouldn\'t work as is, but the changes wouldn\'t be too large. I started by changing my matrix of integers to a matrix of lists of claims, allowing me to specify which claim was touching which square. Once this was done (and my first part was still working), I added some data in the claims to know which claim it conflicted with and how many claims it was in conflict with. With that, I simply returned the identifier of the claim that had no conflicts."},{"id":"/2018/12/02/advent2018-02","metadata":{"permalink":"/2018/12/02/advent2018-02","source":"@site/blog/2018/12-02-advent2018-02.md","title":"Day 2: Inventory Management System","description":"So this time around we\'re working with strings.","date":"2018-12-02T00:00:00.000Z","formattedDate":"December 2, 2018","tags":[{"label":"Challenges","permalink":"/tags/challenges"},{"label":"Advent","permalink":"/tags/advent"},{"label":"C#","permalink":"/tags/c"}],"readingTime":1.51,"hasTruncateMarker":true,"authors":[],"frontMatter":{"title":"Day 2: Inventory Management System","tags":["Challenges","Advent","C#"]},"prevItem":{"title":"Day 3: No Matter How You Slice It","permalink":"/2018/12/03/advent2018-03"},"nextItem":{"title":"Day 1: Chronal Calibration","permalink":"/2018/12/01/advent2018-01"}},"content":"So this time around we\'re working with strings.\\n\\n\x3c!-- truncate --\x3e\\n\\nThe first part asks to build a simple checksum type algorithm to ensure the box ids are correct. I ended up solving it with basically just LINQ in C#.\\n\\n```C#\\nvar counts = ids.Select(s => s.GroupBy(c => c).Select(g => g.Count()))\\n    .Select(cs =>\\n    {\\n        var csl = cs.ToList();\\n        return new[] {csl.Contains(2), csl.Contains(3)};\\n    })\\n    .ToList();\\nreturn (counts.Count(c => c[0]) * counts.Count(c => c[1])).ToString();\\n```\\n\\nThe first ```Select``` returns the number of each character for each id. The second ```Select``` returns whether those counts contain 2 and 3, meaning the id contains a character twice or contains a character thrice. The last part just multiplies the number of ids containing a multiple of 2 by the number of ids containing a multiple of 3.\\n\\n\\nThe second part asks us to find the two matching boxes by finding the two ids that differ by only 1 character. Here I went with a simple brute force of checking all the pairs and returning the first one that matches the criteria.\\n\\n```C#\\nforeach (var id1 in ids)\\n{\\n    foreach (var id2 in ids)\\n    {\\n        if (id1 == id2)\\n            continue;\\n            var commonLetters = string.Concat(id1.Zip(id2, (c1, c2) => c1 == c2 ? c1 : \' \').Where(c => c != \' \'));\\n            if (commonLetters.Length == id1.Length - 1)\\n                return commonLetters;\\n    }\\n}\\n```\\n\\nI opted again for LINQ to calculate the matching characters. If the two characters match, I return it, otherwise I replace it with a space character which I then remove. The first pair which has 1 less common letters than the number of letters in the id is the one we want. I was afraid running a ```O(n\xb2)``` algorithm would require too much compute time, but the input was small enough that I didn\'t need any optimization."},{"id":"/2018/12/01/advent2018-01","metadata":{"permalink":"/2018/12/01/advent2018-01","source":"@site/blog/2018/12-01-advent2018-01.md","title":"Day 1: Chronal Calibration","description":"The first day of the advent of code challenge starts off pretty slowly. You basically just need to sum the numbers up. I\'ve done this by just replacing the end of lines by a space and surrounding it in a LISP sum expression `(+ ...)`.","date":"2018-12-01T00:00:00.000Z","formattedDate":"December 1, 2018","tags":[{"label":"Challenges","permalink":"/tags/challenges"},{"label":"Advent","permalink":"/tags/advent"},{"label":"C#","permalink":"/tags/c"}],"readingTime":0.83,"hasTruncateMarker":true,"authors":[],"frontMatter":{"title":"Day 1: Chronal Calibration","tags":["Challenges","Advent","C#"]},"prevItem":{"title":"Day 2: Inventory Management System","permalink":"/2018/12/02/advent2018-02"},"nextItem":{"title":"Advent of Code","permalink":"/2018/11/27/advent"}},"content":"The first day of the advent of code challenge starts off pretty slowly. You basically just need to sum the numbers up. I\'ve done this by just replacing the end of lines by a space and surrounding it in a LISP sum expression ```(+ ...)```.\\n\\n\x3c!-- truncate --\x3e\\n\\nThe second part required more work though, so I wrote a simple program to solve it. Fortunately, we are given a couple of examples that we can use as unit test cases.\\n\\nI ended up creating a program in C# to do this using a simple loop. I also used this occasion to setup a couple of classes that I will probably be using for future problems, like a simple command line interface to all the solvers as well as a file reader to return all the integers in the file as a list.\\n\\nI also added the first part of the problem in the solution.\\n\\nAll the code is available in my github repository: [advent solutions code](https://github.com/lavoiecsh/lavoiecsh.github.io/tree/master/code/advent2018)."},{"id":"/2018/11/27/advent","metadata":{"permalink":"/2018/11/27/advent","source":"@site/blog/2018/11-27-advent.md","title":"Advent of Code","description":"Small update to announce that my regular posting schedule will be change during the month of december as I will be posting solutions I come up with for the Advent of Code challenge//adventofcode.com/.","date":"2018-11-27T00:00:00.000Z","formattedDate":"November 27, 2018","tags":[{"label":"Challenges","permalink":"/tags/challenges"},{"label":"Advent","permalink":"/tags/advent"},{"label":"C#","permalink":"/tags/c"}],"readingTime":0.51,"hasTruncateMarker":true,"authors":[],"frontMatter":{"title":"Advent of Code","tags":["Challenges","Advent","C#"]},"prevItem":{"title":"Day 1: Chronal Calibration","permalink":"/2018/12/01/advent2018-01"},"nextItem":{"title":"Book Review: Clean Architecture","permalink":"/2018/11/20/cleanarchitecture"}},"content":"Small update to announce that my regular posting schedule will be change during the month of december as I will be posting solutions I come up with for the Advent of Code challenge: https://adventofcode.com/.\\n\\n\x3c!-- truncate --\x3e\\n\\nI have done some of the challenges in the past years, but have never completed the advent during the month of december, so this will be a first for me.\\n\\nI intend to post my solutions as I go and I will probably use differents languages to implement those solutions. I\'m expecting some C#, Javascript, sed/perl mainly, but maybe some F#/Haskell or Python as well."},{"id":"/2018/11/20/cleanarchitecture","metadata":{"permalink":"/2018/11/20/cleanarchitecture","source":"@site/blog/2018/11-20-cleanarchitecture.md","title":"Book Review: Clean Architecture","description":"Next up in the book review series A Craftsman\'s Guide to Software Structure and Design by Robert Martin. Although I\'ve loved a lot of the other books by Uncle Bob, I have to admit this one disappointed me and I\'ll explain why in this book review.","date":"2018-11-20T00:00:00.000Z","formattedDate":"November 20, 2018","tags":[{"label":"Review","permalink":"/tags/review"}],"readingTime":2.795,"hasTruncateMarker":true,"authors":[],"frontMatter":{"title":"Book Review: Clean Architecture","tags":["Review"]},"prevItem":{"title":"Advent of Code","permalink":"/2018/11/27/advent"},"nextItem":{"title":"(Soft|Firm|Hard)ware","permalink":"/2018/11/13/ware"}},"content":"Next up in the book review series: *Clean Architecture: A Craftsman\'s Guide to Software Structure and Design* by Robert Martin. Although I\'ve loved a lot of the other books by Uncle Bob, I have to admit this one disappointed me and I\'ll explain why in this book review.\\n\\n\x3c!-- truncate --\x3e\\n\\nThe book contains 3 main sections:\\n1. A history of software development (parts I and II of the book)\\n2. Principles for software development (parts III and IV of the book)\\n3. Guidelines for software architecture (parts V and VI of the book)\\n\\nThe first section is interesting for cultural knowledge, but not very informative otherwise. It describes some of the advances that made languages what they are today and it explains the reasoning behind a lot of the constraints we have today.\\n\\nThe second section is the \\"theoretical\\" part of the book. The first five chapters describe SOLID principles, which we have all read about in a lot of other books, and the last three describe similar principles defined for components (instead of classes and interfaces). These are important to understand and is the main part of the book.\\n\\nThe third section is an \\"application\\" of the principles describes in the second section. I found a lot of the examples repeated a lot of the information, especially the Details section (part VI). I also think the examples weren\'t complete in the sense that they don\'t really present the solution, only the problem. The last chapter (appropriately named \\"The Missing Chapter\\" as it was written by Simon Brown as what seems to be an attempt to fix the book) presents the best example and describes the options and decisions that would happen in a real world case.\\n\\n### Who is this book for?\\nI\'m still wondering how to answer this question. As described above, the book presents a lot of useless and/or known information to most advanced developers while presenting new information that would be too advanced for novice developers.\\n\\n### What should be read in this book?\\nIf you consider yourself a novice developer, and have never had to work with multiple projects/assemblies/modules: the beginning of the book is excellent for you but you might have trouble understanding the component principles and guidelines, a good challenge nonetheless. If you\'ve worked with bigger projects and would like to understand how other developers/architects in your development teams think: start at the component principles (part IV).\\n\\n### What should be retained from this book?\\nArchitecture is about making the least amount of concrete decisions that would force you in a corner, or about making the most amount of abstract decisions that leave options available, however you want to read it. Some decisions will facilitate development but make deployment harder, others will do the opposite. The component principles help you put SOLID principles (pun intended) around larger groupings of objects to help guide those decisions. Each project is different and must be treated differently in regards to it\'s architecture.\\n\\n### How does proper code apply to clean architecture?\\nClean Architecture was derived from Uncle Bob\'s Clean Code and as such is very relevant in writing proper code. Just like design patterns help make changes and additions to a subset of objects easier down the line, software architecture should help make changes and additions to the whole system easier down the line."},{"id":"/2018/11/13/ware","metadata":{"permalink":"/2018/11/13/ware","source":"@site/blog/2018/11-13-ware.md","title":"(Soft|Firm|Hard)ware","description":"The computer, phone or tablet you\'re reading this on is hardware. The browser that renders it is software. Firmware is somewhere in between. But is it that simple?","date":"2018-11-13T00:00:00.000Z","formattedDate":"November 13, 2018","tags":[{"label":"Practices","permalink":"/tags/practices"}],"readingTime":4.8,"hasTruncateMarker":true,"authors":[],"frontMatter":{"title":"(Soft|Firm|Hard)ware","tags":["Practices"]},"prevItem":{"title":"Book Review: Clean Architecture","permalink":"/2018/11/20/cleanarchitecture"},"nextItem":{"title":"Book Review: Gang of Four","permalink":"/2018/11/06/gangoffour"}},"content":"The computer, phone or tablet you\'re reading this on is hardware. The browser that renders it is software. Firmware is somewhere in between. But is it that simple?\\n\\n\x3c!-- truncate --\x3e\\n\\nI\'ve recently read Clean Architecture by Uncle Bob and loved his definitions of software and hardware:\\n* hardware is anything that is **hard**, rigid, difficult to modify\\n* software on the contrary is **soft**, malleable, easy to modify\\n* firmware is **firm**, not as hard as hardware, nor as soft as software\\n\\nThese definitions might sound simplistic, but their simplicity helps greatly in understanding software development.\\n\\nWhen developing software you can\'t switch out physical components of the machine on which the software is running, nor can you know when the user will do so, so you must develop your software to be as independent of the hardware as possible. You cannot switch out the operating system or drivers of the machine running your software either, so you must ensure that this is separated from your software as well. Some frameworks like Android\'s java framework, C#\'s .NET framework could also be referred to as firmware.\\n\\nOf course when developing you will have to connect to some hardware or firmware. The important thing to remember is that you want these connections to be isolated from the domain, ideally as a plugin to your software. This will mean that your software can easily be ported to another hardware/firmware without too much work.\\n\\nBut the advantage doesn\'t only lie in the ease of porting the software. It also lies in the ease of modifying and testing of the software. If the hardware or firmware updates, you have a lot less code to modify and inversely if you modify business logic, you don\'t need to worry about hardware and firmware bridges. Unit testing pure OO logic is easy to do, but unit testing hardware and firmware is very difficult. This is as true for web developers or game developers as it is for embedded developers.\\n\\nSo what can you do to reduce the coupling between software and firmware/hardware? Move all the code that refers to firmware into a separate project/assembly/module and make it implement an interface that is defined in your software. You\'ll probably notice you can refactor a lot of the code you just extracted because there is a lot of duplication.\\n\\nI\'ll end this with a short example. As many of you know, there\'s been an update to the GDPR and software must now ask for permissions to use certain data (instead of having those permissions granted to us implicitly). Here\'s an example of Android code that shows a popup to the user if he hasn\'t answered the question yet, saves his answer and let\'s him continue if he accepts or logs him out of the system if he refuses.\\n\\n```java\\n//...\\n\\npublic class LoginActivity {\\n    //...\\n    public void login(User user) {\\n        //...\\n        if (user.complianceAcceptanceIsValid()) {\\n            Intent = new Intent(context, DashboardActivity.class);\\n            startActivity(intent);\\n            return;\\n        }\\n        \\n        new AlertDialog.Builder(context)\\n            .setTitle(\\"Compliance Acceptance\\")\\n            .setMessage(R.strings.gdpr_compliance)\\n            .setPositiveButton(\\"Accept\\", new DialogInterface.OnClickListener() {\\n                @Override\\n                public void onClick(DialogInterface dialog, int which) {\\n                    user.onComplianceAccepted(Calendar.getInstance().getTime());\\n                    Intent intent = new Intent(context, DashboardActivity.class);\\n                    startActivity(intent);\\n                }\\n            })\\n            .setNegativeButton(\\"Decline\\", new DialogInterface.OnClickListener() {\\n                @Override\\n                public void onClick(DialogInterface dialog, int which) {\\n                    user.logout();\\n                    Intent intent = new Intent(context, LoginActivity.class);\\n                    startActivity(intent);\\n                }\\n            })\\n            .create()\\n            .show();\\n    }\\n}\\n```\\n\\nNow what is the problem with this code? You have logic code pertaining to the compliance (checking if the user already answer the question, saving the answer, logging the user out) mixed in with an Android Dialog, mixed in with what to do after the user answer the dialog. It\'s very hard to test, and if Android decides to change the API for the AlertDialog, or even remove it, you will probably have a lot of changes to make.\\n\\nSo how can we fix this? By moving the Dialog part into another module:\\n\\n```java\\n//...\\n\\npublic class LoginActivity {\\n    private ComplianceDialog complianceDialog;\\n\\n    //...\\n    public void login(User user) {\\n        //...\\n        complianceDialog.askForCompliance(user, new Dialog.Handler() {\\n            @Override\\n            public void onAccept() {\\n                Intent intent = new Intent(this, DashboardActivity.class);\\n                startActivity(intent);\\n            }\\n            \\n            @Override\\n            public void onDecline() {\\n                Intent intent = new Intent(this, LoginActivity.class);\\n                startActivity(intent);\\n            }\\n        }\\n    }\\n```\\n\\n```java\\n//...\\n\\npublic class ComplianceDialog {\\n    private Dialog dialog;\\n    \\n    public ComplianceDialog(Dialog dialog) {\\n        this.dialog = dialog;\\n    }\\n    \\n    public void askForCompliance(User user, final Dialog.Handler handler) {\\n        if (user.complianceAcceptanceIsValid()) {\\n            handler.onAccept();\\n            return;\\n        }\\n        \\n        dialog.show(\\"Compliance Acceptance\\", \\n            R.strings.gdpr_compliance,\\n            \\"Accept\\",\\n            \\"Decline\\",\\n            new Dialog.Handler() {\\n                @Override\\n                public void onAccept() {\\n                    user.onComplianceAccepted(Calendar.getInstance().getTime());\\n                    handler.onAccept();\\n                }\\n                \\n                @Override\\n                public void onDecline() {\\n                    user.logout();\\n                    handler.onDecline();\\n                }\\n            }));\\n    }\\n}\\n```\\n\\n```java\\npublic interface Dialog {\\n    void show(String title, String message, String accept, String decline, Dialog.Handler handler);\\n    \\n    public static class Handler {\\n        public void onAccept() { }\\n        public void onDecline() { }\\n    }\\n```\\n\\n```java\\n//...\\n\\npublic class DialogImpl implements Dialog {\\n    private Context context;\\n    \\n    public Dialog(Context context) {\\n        this.context = context;\\n    }\\n    \\n    public void show(String title, String message, String accept, String decline, Dialog.Handler handler) {\\n        new AlertDialog.Builder(context)\\n            .setTitle(title)\\n            .setMessage(message)\\n            .setPositiveButton(accept, new DialogInterface.OnClickListener() {\\n                @Override\\n                public void onClick(DialogInterface dialog, int which) {\\n                    handler.onAccept();\\n                }\\n            })\\n            .setNegativeButton(decline, new DialogInterface.OnClickListener() {\\n                @Override\\n                public void onClick(DialogInterface dialog, int which) {\\n                    handler.onDecline();\\n                }\\n            })\\n            .create();\\n            .show();\\n    }\\n}\\n```\\n\\nNow all the user interaction is within one class (ComplianceDialog), the dialog showing is in another class (DialogImpl) and the next activity responsibility is given yet another class (LoginActivity), meaning it can be reused more easily. The ComplianceDialog does not depend on the Android firmware at all. This also allows us to easily test the ComplianceDialog class by mocking or faking the Dialog interface we pass in. The Dialog interface can also be reused anywhere we need a yes/no dialog to be shown (which often happens) so we can probably refactor a lot of the other uses of AlertDialog in the code with this pattern without too much work."},{"id":"/2018/11/06/gangoffour","metadata":{"permalink":"/2018/11/06/gangoffour","source":"@site/blog/2018/11-06-gangoffour.md","title":"Book Review: Gang of Four","description":"I\'m starting this book review series with the infamous book about design patterns. For those who don\'t know which book I\'m talking about Elements of Reusable Object-Oriented Software, written by Erich Gamma, John Vlissides, Ralph Johnson, and Richard Helm.","date":"2018-11-06T00:00:00.000Z","formattedDate":"November 6, 2018","tags":[{"label":"Review","permalink":"/tags/review"}],"readingTime":1.76,"hasTruncateMarker":true,"authors":[],"frontMatter":{"title":"Book Review: Gang of Four","tags":["Review"]},"prevItem":{"title":"(Soft|Firm|Hard)ware","permalink":"/2018/11/13/ware"},"nextItem":{"title":"Proper Code","permalink":"/2018/10/30/propercode"}},"content":"I\'m starting this book review series with the infamous book about design patterns. For those who don\'t know which book I\'m talking about: *Design Patterns: Elements of Reusable Object-Oriented Software*, written by Erich Gamma, John Vlissides, Ralph Johnson, and Richard Helm.\\n\\nThis book has been considered by many as a reference that everybody should read (and I count myself in these as well). I do think the book does not need to be read in it\'s entirety for the reader to use it\'s concepts.\\n\\n\x3c!-- truncate --\x3e\\n\\n### Who is this book for?\\nObject-oriented software developers. This book was written to help solve problems generally found when developing OO software (mostly in Java, C++, C#, Ruby, etc.). Most of the patterns are either already implemented or not necessary in functional and/or procedural languages.\\n\\n### What should be read in this book?\\nThe main thing to read is the \\"Intent\\", \\"Motivation\\", \\"Applicability\\" and \\"Structure\\" sections of each pattern. I think this is a sufficiently small subset of information which you can use to determine when you should apply a pattern and how to recognize it in existing code. The introduction and case studies can also help more novice programmers.\\n\\n### What should be retained from this book?\\nDesign patterns exist and are very useful in simplifying software and allowing software to grow larger without making a mess. This book is also meant to be a reference which can be opened whenever the need to implement or understand a pattern arises.\\n\\n### How does proper code apply to design patterns?\\nDesign patterns greatly help in making your code easier to understand later on and adds a lot of flexibility when you need to make changes to parts of the application. One thing to remember when implementing design patterns is that it is usually a good idea to name participant classes according to the pattern. For example, `EmployeeEndpointLoggingDecorator` for a logging decorator around the employee endpoint, or `EmployeeSubject` and `EmployeeObserver` when implementing the observer pattern. This makes it easier to recognize the pattern when you or someone else returns to the code a year later."},{"id":"/2018/10/30/propercode","metadata":{"permalink":"/2018/10/30/propercode","source":"@site/blog/2018/10-30-propercode.md","title":"Proper Code","description":"I started my programming career in a large waterfall company working on their C++ software. We had multiple layers of analysis documents describing what should be done to implement each feature. We had no unit tests. The software was so large the current version of Visual Studio couldn\'t handle it all. It took so much time to compile (over six hours to compile everything) that we were doing partial compilations refering to a nightly build and it still took over an hour to build if you had enough code modified. Launching the software to test your features often took over 5 minutes. We were working on two different features at the same time because of all the waiting and you worked on your features alone for weeks if not months at a time. The company was hiring developpers by batches of 20 to 30 and giving them two weeks of classes when they started. Refactoring was pretty much out of the question because we couldn\'t deliver features fast enough.","date":"2018-10-30T00:00:00.000Z","formattedDate":"October 30, 2018","tags":[{"label":"Blog","permalink":"/tags/blog"},{"label":"Update","permalink":"/tags/update"}],"readingTime":1.79,"hasTruncateMarker":true,"authors":[],"frontMatter":{"title":"Proper Code","tags":["Blog","Update"]},"prevItem":{"title":"Book Review: Gang of Four","permalink":"/2018/11/06/gangoffour"},"nextItem":{"title":"Introduction","permalink":"/2018/09/20/indroduction"}},"content":"I started my programming career in a large waterfall company working on their C++ software. We had multiple layers of analysis documents describing what should be done to implement each feature. We had no unit tests. The software was so large the current version of Visual Studio couldn\'t handle it all. It took so much time to compile (over six hours to compile everything) that we were doing partial compilations refering to a nightly build and it still took over an hour to build if you had enough code modified. Launching the software to test your features often took over 5 minutes. We were working on two different features at the same time because of all the waiting and you worked on your features alone for weeks if not months at a time. The company was hiring developpers by batches of 20 to 30 and giving them two weeks of classes when they started. Refactoring was pretty much out of the question because we couldn\'t deliver features fast enough.\\n\\n\x3c!-- truncate --\x3e\\n\\nI then switched to a smaller company working in an agile process. I learned about not writing analysis documents, sprint reviews, retros and plannings, unit testing, refactoring, compile and execute cycles requiring seconds instead of minutes. They taught me about Uncle Bob and Clean Code and even offered me to go follow one of his classes.\\n\\nIt surprised me how much he was accurate when talking about large companies as it was exactly what I had lived previously. It encouraged me to continue learning even more about clean coding, Test Driven Development (TDD), Domain Driven Design (DDD), architecture and to transfer my knowledge to others around me. It started with doing small sessions with my coworkers, and it is now evolving into this blog.\\n\\nSo what is Proper Code? It\'s everything surrounding clean code, TDD, DDD, architecture. How to code properly so it\'s easy to make changes down the line and so that the development process doesn\'t slow down as the code base grows. It\'s also best practices of the languages and frameworks you work with and knowing the new developments for those languages and frameworks."},{"id":"/2018/09/20/indroduction","metadata":{"permalink":"/2018/09/20/indroduction","source":"@site/blog/2018/09-20-indroduction.md","title":"Introduction","description":"Welcome to my blog.","date":"2018-09-20T00:00:00.000Z","formattedDate":"September 20, 2018","tags":[{"label":"Blog","permalink":"/tags/blog"},{"label":"Update","permalink":"/tags/update"}],"readingTime":0.41,"hasTruncateMarker":true,"authors":[],"frontMatter":{"title":"Introduction","tags":["Blog","Update"]},"prevItem":{"title":"Proper Code","permalink":"/2018/10/30/propercode"}},"content":"Welcome to my blog.\\n\\n\x3c!-- truncate --\x3e\\n\\nI\'m starting this blog as an opportunity to talk about software development. My objective here is to provide my opinion on different subjects pertaining to software development, and maybe teach you new stuff.\\n\\nMy plan is to write about general development practices as well as more specific C#, dotnet core news. Blog posts should be short and uploaded every week or two at the maximum.\\n\\nI will also be translating the blog posts in French."}]}')}}]);